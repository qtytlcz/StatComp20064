<!DOCTYPE html>

<html>

<head>

<meta charset="utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />

<meta name="viewport" content="width=device-width, initial-scale=1" />

<meta name="author" content="20064" />

<meta name="date" content="2020-12-22" />

<title>Introduction to StatComp20064</title>


<style type="text/css">
  code{white-space: pre-wrap;}
  span.smallcaps{font-variant: small-caps;}
  span.underline{text-decoration: underline;}
  div.column{display: inline-block; vertical-align: top; width: 50%;}
  div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
  ul.task-list{list-style: none;}
    </style>


<style type="text/css">code{white-space: pre;}</style>
<style type="text/css" data-origin="pandoc">
div.sourceCode { overflow-x: auto; }
table.sourceCode, tr.sourceCode, td.lineNumbers, td.sourceCode {
  margin: 0; padding: 0; vertical-align: baseline; border: none; }
table.sourceCode { width: 100%; line-height: 100%; }
td.lineNumbers { text-align: right; padding-right: 4px; padding-left: 4px; color: #aaaaaa; border-right: 1px solid #aaaaaa; }
td.sourceCode { padding-left: 5px; }
code > span.kw { color: #007020; font-weight: bold; } /* Keyword */
code > span.dt { color: #902000; } /* DataType */
code > span.dv { color: #40a070; } /* DecVal */
code > span.bn { color: #40a070; } /* BaseN */
code > span.fl { color: #40a070; } /* Float */
code > span.ch { color: #4070a0; } /* Char */
code > span.st { color: #4070a0; } /* String */
code > span.co { color: #60a0b0; font-style: italic; } /* Comment */
code > span.ot { color: #007020; } /* Other */
code > span.al { color: #ff0000; font-weight: bold; } /* Alert */
code > span.fu { color: #06287e; } /* Function */
code > span.er { color: #ff0000; font-weight: bold; } /* Error */
code > span.wa { color: #60a0b0; font-weight: bold; font-style: italic; } /* Warning */
code > span.cn { color: #880000; } /* Constant */
code > span.sc { color: #4070a0; } /* SpecialChar */
code > span.vs { color: #4070a0; } /* VerbatimString */
code > span.ss { color: #bb6688; } /* SpecialString */
code > span.im { } /* Import */
code > span.va { color: #19177c; } /* Variable */
code > span.cf { color: #007020; font-weight: bold; } /* ControlFlow */
code > span.op { color: #666666; } /* Operator */
code > span.bu { } /* BuiltIn */
code > span.ex { } /* Extension */
code > span.pp { color: #bc7a00; } /* Preprocessor */
code > span.at { color: #7d9029; } /* Attribute */
code > span.do { color: #ba2121; font-style: italic; } /* Documentation */
code > span.an { color: #60a0b0; font-weight: bold; font-style: italic; } /* Annotation */
code > span.cv { color: #60a0b0; font-weight: bold; font-style: italic; } /* CommentVar */
code > span.in { color: #60a0b0; font-weight: bold; font-style: italic; } /* Information */

</style>
<script>
// apply pandoc div.sourceCode style to pre.sourceCode instead
(function() {
  var sheets = document.styleSheets;
  for (var i = 0; i < sheets.length; i++) {
    if (sheets[i].ownerNode.dataset["origin"] !== "pandoc") continue;
    try { var rules = sheets[i].cssRules; } catch (e) { continue; }
    for (var j = 0; j < rules.length; j++) {
      var rule = rules[j];
      // check if there is a div.sourceCode rule
      if (rule.type !== rule.STYLE_RULE || rule.selectorText !== "div.sourceCode") continue;
      var style = rule.style.cssText;
      // check if color or background-color is set
      if (rule.style.color === '' && rule.style.backgroundColor === '') continue;
      // replace div.sourceCode by a pre.sourceCode rule
      sheets[i].deleteRule(j);
      sheets[i].insertRule('pre.sourceCode{' + style + '}', j);
    }
  }
})();
</script>




<link href="data:text/css;charset=utf-8,body%20%7B%0Abackground%2Dcolor%3A%20%23fff%3B%0Amargin%3A%201em%20auto%3B%0Amax%2Dwidth%3A%20700px%3B%0Aoverflow%3A%20visible%3B%0Apadding%2Dleft%3A%202em%3B%0Apadding%2Dright%3A%202em%3B%0Afont%2Dfamily%3A%20%22Open%20Sans%22%2C%20%22Helvetica%20Neue%22%2C%20Helvetica%2C%20Arial%2C%20sans%2Dserif%3B%0Afont%2Dsize%3A%2014px%3B%0Aline%2Dheight%3A%201%2E35%3B%0A%7D%0A%23TOC%20%7B%0Aclear%3A%20both%3B%0Amargin%3A%200%200%2010px%2010px%3B%0Apadding%3A%204px%3B%0Awidth%3A%20400px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Aborder%2Dradius%3A%205px%3B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Afont%2Dsize%3A%2013px%3B%0Aline%2Dheight%3A%201%2E3%3B%0A%7D%0A%23TOC%20%2Etoctitle%20%7B%0Afont%2Dweight%3A%20bold%3B%0Afont%2Dsize%3A%2015px%3B%0Amargin%2Dleft%3A%205px%3B%0A%7D%0A%23TOC%20ul%20%7B%0Apadding%2Dleft%3A%2040px%3B%0Amargin%2Dleft%3A%20%2D1%2E5em%3B%0Amargin%2Dtop%3A%205px%3B%0Amargin%2Dbottom%3A%205px%3B%0A%7D%0A%23TOC%20ul%20ul%20%7B%0Amargin%2Dleft%3A%20%2D2em%3B%0A%7D%0A%23TOC%20li%20%7B%0Aline%2Dheight%3A%2016px%3B%0A%7D%0Atable%20%7B%0Amargin%3A%201em%20auto%3B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dcolor%3A%20%23DDDDDD%3B%0Aborder%2Dstyle%3A%20outset%3B%0Aborder%2Dcollapse%3A%20collapse%3B%0A%7D%0Atable%20th%20%7B%0Aborder%2Dwidth%3A%202px%3B%0Apadding%3A%205px%3B%0Aborder%2Dstyle%3A%20inset%3B%0A%7D%0Atable%20td%20%7B%0Aborder%2Dwidth%3A%201px%3B%0Aborder%2Dstyle%3A%20inset%3B%0Aline%2Dheight%3A%2018px%3B%0Apadding%3A%205px%205px%3B%0A%7D%0Atable%2C%20table%20th%2C%20table%20td%20%7B%0Aborder%2Dleft%2Dstyle%3A%20none%3B%0Aborder%2Dright%2Dstyle%3A%20none%3B%0A%7D%0Atable%20thead%2C%20table%20tr%2Eeven%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Ap%20%7B%0Amargin%3A%200%2E5em%200%3B%0A%7D%0Ablockquote%20%7B%0Abackground%2Dcolor%3A%20%23f6f6f6%3B%0Apadding%3A%200%2E25em%200%2E75em%3B%0A%7D%0Ahr%20%7B%0Aborder%2Dstyle%3A%20solid%3B%0Aborder%3A%20none%3B%0Aborder%2Dtop%3A%201px%20solid%20%23777%3B%0Amargin%3A%2028px%200%3B%0A%7D%0Adl%20%7B%0Amargin%2Dleft%3A%200%3B%0A%7D%0Adl%20dd%20%7B%0Amargin%2Dbottom%3A%2013px%3B%0Amargin%2Dleft%3A%2013px%3B%0A%7D%0Adl%20dt%20%7B%0Afont%2Dweight%3A%20bold%3B%0A%7D%0Aul%20%7B%0Amargin%2Dtop%3A%200%3B%0A%7D%0Aul%20li%20%7B%0Alist%2Dstyle%3A%20circle%20outside%3B%0A%7D%0Aul%20ul%20%7B%0Amargin%2Dbottom%3A%200%3B%0A%7D%0Apre%2C%20code%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0Aborder%2Dradius%3A%203px%3B%0Acolor%3A%20%23333%3B%0Awhite%2Dspace%3A%20pre%2Dwrap%3B%20%0A%7D%0Apre%20%7B%0Aborder%2Dradius%3A%203px%3B%0Amargin%3A%205px%200px%2010px%200px%3B%0Apadding%3A%2010px%3B%0A%7D%0Apre%3Anot%28%5Bclass%5D%29%20%7B%0Abackground%2Dcolor%3A%20%23f7f7f7%3B%0A%7D%0Acode%20%7B%0Afont%2Dfamily%3A%20Consolas%2C%20Monaco%2C%20%27Courier%20New%27%2C%20monospace%3B%0Afont%2Dsize%3A%2085%25%3B%0A%7D%0Ap%20%3E%20code%2C%20li%20%3E%20code%20%7B%0Apadding%3A%202px%200px%3B%0A%7D%0Adiv%2Efigure%20%7B%0Atext%2Dalign%3A%20center%3B%0A%7D%0Aimg%20%7B%0Abackground%2Dcolor%3A%20%23FFFFFF%3B%0Apadding%3A%202px%3B%0Aborder%3A%201px%20solid%20%23DDDDDD%3B%0Aborder%2Dradius%3A%203px%3B%0Aborder%3A%201px%20solid%20%23CCCCCC%3B%0Amargin%3A%200%205px%3B%0A%7D%0Ah1%20%7B%0Amargin%2Dtop%3A%200%3B%0Afont%2Dsize%3A%2035px%3B%0Aline%2Dheight%3A%2040px%3B%0A%7D%0Ah2%20%7B%0Aborder%2Dbottom%3A%204px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Apadding%2Dbottom%3A%202px%3B%0Afont%2Dsize%3A%20145%25%3B%0A%7D%0Ah3%20%7B%0Aborder%2Dbottom%3A%202px%20solid%20%23f7f7f7%3B%0Apadding%2Dtop%3A%2010px%3B%0Afont%2Dsize%3A%20120%25%3B%0A%7D%0Ah4%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23f7f7f7%3B%0Amargin%2Dleft%3A%208px%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Ah5%2C%20h6%20%7B%0Aborder%2Dbottom%3A%201px%20solid%20%23ccc%3B%0Afont%2Dsize%3A%20105%25%3B%0A%7D%0Aa%20%7B%0Acolor%3A%20%230033dd%3B%0Atext%2Ddecoration%3A%20none%3B%0A%7D%0Aa%3Ahover%20%7B%0Acolor%3A%20%236666ff%3B%20%7D%0Aa%3Avisited%20%7B%0Acolor%3A%20%23800080%3B%20%7D%0Aa%3Avisited%3Ahover%20%7B%0Acolor%3A%20%23BB00BB%3B%20%7D%0Aa%5Bhref%5E%3D%22http%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0Aa%5Bhref%5E%3D%22https%3A%22%5D%20%7B%0Atext%2Ddecoration%3A%20underline%3B%20%7D%0A%0Acode%20%3E%20span%2Ekw%20%7B%20color%3A%20%23555%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Edt%20%7B%20color%3A%20%23902000%3B%20%7D%20%0Acode%20%3E%20span%2Edv%20%7B%20color%3A%20%2340a070%3B%20%7D%20%0Acode%20%3E%20span%2Ebn%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Efl%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Ech%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Est%20%7B%20color%3A%20%23d14%3B%20%7D%20%0Acode%20%3E%20span%2Eco%20%7B%20color%3A%20%23888888%3B%20font%2Dstyle%3A%20italic%3B%20%7D%20%0Acode%20%3E%20span%2Eot%20%7B%20color%3A%20%23007020%3B%20%7D%20%0Acode%20%3E%20span%2Eal%20%7B%20color%3A%20%23ff0000%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Efu%20%7B%20color%3A%20%23900%3B%20font%2Dweight%3A%20bold%3B%20%7D%20%0Acode%20%3E%20span%2Eer%20%7B%20color%3A%20%23a61717%3B%20background%2Dcolor%3A%20%23e3d2d2%3B%20%7D%20%0A" rel="stylesheet" type="text/css" />




</head>

<body>




<h1 class="title toc-ignore">Introduction to StatComp20064</h1>
<h4 class="author">20064</h4>
<h4 class="date">2020-12-22</h4>



<div id="overview" class="section level2">
<h2>Overview</h2>
<p><strong>StatComp20064</strong> is a simple R package developed to learn how to correctly generate and compile R packages. Due to the needs for the course statistical computing, all of the homeworks are below. But in order to avoid running for too long we annotate some functions, which needs too much iteration.</p>
<p>Apart from homework, we also wrote two functions <strong>scadest</strong> and <strong>BinaryPoisson</strong>.</p>
<hr />
</div>
<div id="homework" class="section level2">
<h2>Homework</h2>
<hr />
</div>
<div id="question" class="section level2">
<h2>Question</h2>
<p><strong>Familiar with package knitr and use it flexibly.</strong></p>
</div>
<div id="answer-1" class="section level2">
<h2>Answer 1</h2>
<p><strong>Output the statistical results of the iris data set:</strong></p>
<table>
<thead>
<tr class="header">
<th align="left"></th>
<th align="left">Sepal.Length</th>
<th align="left">Sepal.Width</th>
<th align="left">Petal.Length</th>
<th align="left">Petal.Width</th>
<th align="left">Species</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left"></td>
<td align="left">Min. :4.300</td>
<td align="left">Min. :2.000</td>
<td align="left">Min. :1.000</td>
<td align="left">Min. :0.100</td>
<td align="left">setosa :50</td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="left">1st Qu.:5.100</td>
<td align="left">1st Qu.:2.800</td>
<td align="left">1st Qu.:1.600</td>
<td align="left">1st Qu.:0.300</td>
<td align="left">versicolor:50</td>
</tr>
<tr class="odd">
<td align="left"></td>
<td align="left">Median :5.800</td>
<td align="left">Median :3.000</td>
<td align="left">Median :4.350</td>
<td align="left">Median :1.300</td>
<td align="left">virginica :50</td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="left">Mean :5.843</td>
<td align="left">Mean :3.057</td>
<td align="left">Mean :3.758</td>
<td align="left">Mean :1.199</td>
<td align="left">NA</td>
</tr>
<tr class="odd">
<td align="left"></td>
<td align="left">3rd Qu.:6.400</td>
<td align="left">3rd Qu.:3.300</td>
<td align="left">3rd Qu.:5.100</td>
<td align="left">3rd Qu.:1.800</td>
<td align="left">NA</td>
</tr>
<tr class="even">
<td align="left"></td>
<td align="left">Max. :7.900</td>
<td align="left">Max. :4.400</td>
<td align="left">Max. :6.900</td>
<td align="left">Max. :2.500</td>
<td align="left">NA</td>
</tr>
</tbody>
</table>
</div>
<div id="answer-2" class="section level2">
<h2>Answer 2</h2>
<p><strong>Use the four features of the iris data set for visual analysis.</strong> <img src="data:image/png;base64,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" /><!-- --></p>
</div>
<div id="answer-3" class="section level2">
<h2>Answer 3</h2>
<p><strong>Generally, we will use the similarity based on Pearson correlation to perform cluster analysis on the iris data set. Next, we will give the definition of Pearson correlation:</strong></p>
<p><span class="math display">\[\rho_{X,Y}=\frac{cov(X,Y)}{\sigma_{X}\sigma_{Y}}\]</span></p>
<p><strong>The follow-up work is still going on. So thanks for reading.</strong></p>
<hr />
</div>
<div id="exercise-3.3" class="section level2">
<h2>Exercise 3.3</h2>
<div id="question-1" class="section level3">
<h3>Question</h3>
<p><strong>Use the derived inverse probability transformation to generate random numbers of Pareto(2,2), and use visual methods to verify.</strong></p>
</div>
<div id="answer" class="section level3">
<h3>Answer</h3>
<p><strong>Here <span class="math inline">\(F(x)=1-(\frac{b}{x})^a \quad for \quad x\geq b&gt;0,a&gt;0\)</span> and <span class="math inline">\(F_{X}^{-1}(u)=\frac{b}{\sqrt[a]{(1-u)}} \quad for \quad 0\leq u &lt;1.\)</span> Generate all n required random uniform numbers as vector u.Then <span class="math inline">\(F_{X}^{-1}(u)\)</span> is a vector of length n containing the sample <span class="math inline">\(x_{1}, . . . , x_{n}.\)</span>(The value of the parameter has been brought in.)</strong></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">n &lt;-<span class="st"> </span><span class="dv">10000</span>
u &lt;-<span class="st"> </span><span class="kw">runif</span>(n)
x &lt;-<span class="st"> </span><span class="dv">2</span> <span class="op">/</span><span class="st"> </span>((<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>u) <span class="op">^</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">/</span><span class="st"> </span><span class="dv">2</span>))
<span class="co">#After many attempts, discard some values with low probability of occurrence, and select appropriate coordinates for drawing</span>
x &lt;-<span class="st"> </span>x[x <span class="op">&lt;=</span><span class="st"> </span><span class="dv">10</span>]
y &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">1</span>, <span class="dv">10</span>, <span class="fl">0.5</span>)
<span class="kw">hist</span>(
x,
<span class="dt">prob =</span> <span class="ot">TRUE</span>,
<span class="dt">breaks =</span> y,
<span class="dt">main =</span> <span class="st">&quot;the density histogram of the sample&quot;</span>,
<span class="dt">xlab =</span> <span class="st">&quot;random variates&quot;</span>
)
y &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">2</span>, <span class="dv">10</span>, <span class="fl">0.1</span>)
<span class="kw">lines</span>(y, <span class="dv">8</span> <span class="op">/</span><span class="st"> </span>(y <span class="op">^</span><span class="st"> </span><span class="dv">3</span>), <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">lwd =</span> <span class="dv">2</span>)</code></pre></div>
<p><img src="data:image/png;base64,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" /><!-- --></p>
<p><strong>The histogram and density plot above suggests that the empirical and theoretical distributions approximately agree.</strong></p>
<hr />
</div>
</div>
<div id="exercise-3.9" class="section level2">
<h2>Exercise 3.9</h2>
<div id="question-2" class="section level3">
<h3>Question</h3>
<p><strong>Generate random numbers as required and estimate the density function.</strong></p>
</div>
<div id="answer-4" class="section level3">
<h3>Answer</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">n &lt;-<span class="st"> </span><span class="dv">10000</span>
u1 &lt;-<span class="st"> </span><span class="kw">runif</span>(n, <span class="dt">min =</span> <span class="op">-</span><span class="dv">1</span>, <span class="dt">max =</span> <span class="dv">1</span>)
u2 &lt;-<span class="st"> </span><span class="kw">runif</span>(n, <span class="dt">min =</span> <span class="op">-</span><span class="dv">1</span>, <span class="dt">max =</span> <span class="dv">1</span>)
u3 &lt;-<span class="st"> </span><span class="kw">runif</span>(n, <span class="dt">min =</span> <span class="op">-</span><span class="dv">1</span>, <span class="dt">max =</span> <span class="dv">1</span>)
u4 &lt;-<span class="st"> </span>u3
u4 &lt;-<span class="st"> </span>u2[(<span class="kw">abs</span>(u3) <span class="op">&gt;</span><span class="st"> </span><span class="kw">abs</span>(u2)) <span class="op">&amp;</span><span class="st"> </span>(<span class="kw">abs</span>(u3) <span class="op">&gt;</span><span class="st"> </span><span class="kw">abs</span>(u1))]
<span class="kw">hist</span>(
  u4,
  <span class="dt">prob =</span> <span class="ot">TRUE</span>,
  <span class="dt">breaks =</span> <span class="kw">seq</span>(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="fl">0.1</span>),
  <span class="dt">main =</span> <span class="st">&quot;the density histogram of the sample&quot;</span>,
  <span class="dt">xlab =</span> <span class="st">&quot;random variates&quot;</span>
)
y &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="op">-</span><span class="dv">1</span>, <span class="dv">1</span>, <span class="fl">0.025</span>)
<span class="kw">lines</span>(y, <span class="fl">0.75</span> <span class="op">*</span><span class="st"> </span>(<span class="dv">1</span> <span class="op">-</span><span class="st"> </span>y <span class="op">^</span><span class="st"> </span><span class="dv">2</span>), <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">lwd =</span> <span class="dv">2</span>)</code></pre></div>
<p><img src="data:image/png;base64,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" /><!-- --></p>
<p><strong>The histogram and density plot above suggests that the empirical and theoretical distributions approximately agree.</strong></p>
<hr />
</div>
</div>
<div id="exercise-3.10" class="section level2">
<h2>Exercise 3.10</h2>
<div id="question-3" class="section level3">
<h3>Question</h3>
<p><strong>Prove that the algorithm given in Exercise 3.9 generates variates from the density <span class="math inline">\(f_{e}.\)</span></strong></p>
</div>
<div id="answer-5" class="section level3">
<h3>Answer</h3>
<strong>Let V be the random variates and take <span class="math inline">\(\alpha\in(0,1)\)</span> randomly. According to<span class="math display">\[P(|v|\leq\alpha)=P(max(|u_{1}|,|u_{2}|)\leq |u_{3}| and |u_{2}|\leq\alpha)+P(max(|u_{1}|,|u_{2}|)&gt;|u_{3}| and |u_{3}|)\leq\alpha),\]</span> we have </strong>
<span class="math display">\[\begin{equation}\nonumber\begin{aligned}P(|v|\leq\alpha)&amp;=\int_{0}^{\alpha}(\int_{0}^{u_{2}}(1-u_{2})du_{1}+\int_{u_{2}}^{1}(1-u_{1})du_{1})du_{2}+\int_{0}^{\alpha}(1-u_{3}^{2})du_{3}\\ &amp;=\frac{3\alpha-\alpha^{3}}{2}.\end{aligned}\end{equation}\]</span>
<p><strong>So we get<span class="math display">\[P(0\leq v\leq\alpha)=\frac{3\alpha-\alpha^{3}}{4}\]</span></strong> <strong>From the symmetry of the random variable and the differentiability of the probability obtained above, we can determine that the density function of the random variable exists and can be expressed as:<span class="math display">\[f_{v}(\alpha)=\frac{3}{4}(1-\alpha^{2}),\alpha\in(-1,1).\]</span></strong></p>
<hr />
</div>
</div>
<div id="exercise-3.13" class="section level2">
<h2>Exercise 3.13</h2>
<div id="question-4" class="section level3">
<h3>Question</h3>
<p><strong>Generate 1000 random observations from the mixture with r = 4 and beta = 2. Then compare the empirical and theoretical Pareto distributions by using visual methods.</strong></p>
</div>
<div id="answer-6" class="section level3">
<h3>Answer</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">n &lt;-<span class="st"> </span><span class="dv">1000</span>
r &lt;-<span class="st"> </span><span class="dv">4</span>
beta &lt;-<span class="st"> </span><span class="dv">2</span>
lambda &lt;-<span class="st"> </span><span class="kw">rgamma</span>(n, r, beta)
x &lt;-<span class="st"> </span><span class="kw">rexp</span>(n, lambda)
<span class="co">#After many attempts, discard some values with low probability of occurrence, and select appropriate coordinates for drawing</span>
x &lt;-<span class="st"> </span>x[x <span class="op">&lt;=</span><span class="st"> </span><span class="dv">6</span>]
<span class="kw">hist</span>(
  x,
  <span class="dt">prob =</span> <span class="ot">TRUE</span>,
  <span class="dt">breaks =</span> <span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">6</span>, <span class="fl">0.5</span>),
  <span class="dt">main =</span> <span class="st">&quot;the density histogram of the sample&quot;</span>,
  <span class="dt">xlab =</span> <span class="st">&quot;random variates&quot;</span>
)
y &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">0</span>, <span class="dv">6</span>, <span class="fl">0.025</span>)
<span class="kw">lines</span>(y, <span class="dv">64</span> <span class="op">/</span><span class="st"> </span>(<span class="dv">2</span> <span class="op">+</span><span class="st"> </span>y) <span class="op">^</span><span class="st"> </span><span class="dv">5</span>, <span class="dt">col =</span> <span class="st">&quot;red&quot;</span>, <span class="dt">lwd =</span> <span class="dv">2</span>)</code></pre></div>
<p><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAASAAAAEgCAMAAAAjXV6yAAAAw1BMVEUAAAAAADoAAGYAOjoAOmYAOpAAZpAAZrY6AAA6ADo6AGY6OgA6Ojo6OmY6OpA6ZpA6ZrY6kLY6kNtmAABmADpmOgBmOjpmZmZmkLZmkNtmtrZmtttmtv+QOgCQZgCQZjqQkDqQkGaQkLaQtpCQttuQtv+Q29uQ2/+2ZgC2Zjq2ZpC2kDq2kGa225C229u22/+2/7a2///T09PbkDrbkGbbtmbbtpDb27bb29vb////AAD/tmb/25D/27b//7b//9v////Tl/gVAAAACXBIWXMAAA7DAAAOwwHHb6hkAAANlElEQVR4nO1da2PbthU9duxJm9etlZLukbhdtrZmuocbq01n0ZH1/39VAVyCBCWAIETS95Li+SBTBHBwcIwXSRDCfkYjwC1AOsAtQDrALUA6wC1AOsAtQDrALUA6wC1AOsAtQDrALUA6wC1AOsAtQDrALUA6wC1AOsAtQDrALUA6wC1AOsAtQDrALUA6wC1AOsAtQDrALUA6wC1AOsAtQDrALUA6wC1AOsAtQDrALUA6wC1AOsAtQDrALUA6wC1AOsAtQDrw/OPH/X6Di7tIxAyXH+N0z7e4flR/fvTEdTIporkJfSk64fnDEvjSYW9RSA/w5rJ/gz6/8cVtMsifohNyKKwc9hMNQq8GNcVtyiSFvSWc7LK2hfRA23z5UaX94QNwZQie1dHFl9U/WNfVq+8okyqsluTnG3X6z/dF1cg06cUNFjpI/SPflYptiqIGlckykrHff/oaePXXRyvj6s5kq1L+6w0u7/ef3qh4XyiC3RqLTze4eLv/eVloIJQEJOKO/IkXspSyP8jEpiVojeq0xpX9j6rClIFOmE2iNWzKCJVBl/+gSlHVDScTMqhKZg0qzphu7LawuTx9/ZiXWRZCgBsru5aHIvAZFC5kJWV/lAnVPlzf68+VKdH9/mlZNF+TYPGoDTcFKcNU5KsiiXb6cf+LPqSSG1NUtHf0X6hE2ExMNCdZYaNKQr6tbLaZ9U2l/L9K9btHyl5rX+m0eFvEN3AJPE0sWMh6CWqZlAZRYVb0oc/Yf0tmLb/86IZREkW00B9X/yurmzVIHS7cFuZmYqI5yYpMMqfSOdkWKQ1+/Y+qMwt9XuVDn84/0yXwGRQqpCvlIBO3kzb/bRW3ajtU5IXNxA1zklBrMC3fMYiyz6rhqp7i+tFJVlp6XXRvd/a4Vtbnbyn7RVEx6bMyyCUIddKhQpZSDjI5MqhogmVa20Z0Jm6Yk0QNo3T2+5pBuo0V/yqvQU4ySmGz0rXOzdaWVRfj6p+/roMGuQSNBh0Wsl6CWia+GmSrc+2/UtSgMsw1SGXw/sb0ja5Buu65Q+uRQVWydjWInNiFDUqpQbVCOlIOMzkyyOlVXXbbB5VhdYO0um9UDNcgHeXGmRB6DLLJon2QKWtuu71VwKBYHxQuZCXlMBM7TlelzfTs4vO6LIE7nDhh9Qr7lWkwtgZV//FqgDk2yElWhIVHMct3/fj5NtwHhUaxTayQjpTDTOwUoUpbjP5V08iq+YMT5ib5UDZoMiiHne24E+SjGlQlsymC86CyD2rspN15kGtQHi1krQT1TlrPLe9r7eXzt+o/T5NKqnn/XuLVW6qmVVgtyS+6/X5hZ9I0Cb6nWlDV4OMmViYrU5iJ8N8oW3XqT/dHo9jVd5uysR8b5BC4l37xQjpS6pnguCn2B2cSdCqcaQIPMCC3atOnX4Jm5l6FmYiyAoMxm2a+iscLwE5Vqr6QBxiMWRl08VWH9J+/XpYX2IwAc/7iAW4B0gFuAdIBbgHSAW4B0gFuAdIBbgHSAW4B0gFuAdIBbgHSAW4B0gFuAdIBbgHSAW4B0gFuAdIBbgHSAW4B0gFuAdIBbgHSAW4B0gFuAdIBbgHSAW4B0gFuAdIBbgHSAW4B0gFuAdKBwZi328GoXxIYjnoaDmE46tmgCGaDwqQG222xBmqILF4MGIT0QWO7NX8eBsnixYBBSGeDIqQPrkODZPFiwCCks0ER0tmgCOlsUIR0NihCOhsUIZ0NipDOBkVIZ4MOWUrQ19mgZrrCoMKhnrN4YWAIutmgCN1sUIRuNihCNxsUobMGkUM9Z/HCwBB052tQBizMm/eht72J7mwN2ph9Ocwb/YHXmYnuXA16vtV7apj3tDeB1/2J7lwN2q1Vy8rNXgF5YMcAojtXg+YaFEPZBxmrwnSTNMi/59ABznsU23Taa8OlKw0yDqExhXSg9q2zR0Q3XYPIohZ72mzajWJTMyg3vcvzbfKeRv47ihMzSO/3Q86EJjmt6SqDtENoTCEdsAe7dR9bGRHdNA16Tf40Vh+7RVwwDtFN2qBQ92vC7BCXh8Y6opugQVnVzYaHeWf+3PJSYzoGVTWoAeZildDyYnVKBrXAedegNtjYa7D2fZByKCkLcYD53K1X5S7xTaOYjRScSRLd9AzqmW42KELnGvQw8gX3KI/0jfhNQ+tJoJumQZnebHqxzzptLkt0kzRIT3JyNUp1uFLdT96gTG9uPRtUA8qjbLFb659LmZtYDSiP9PbGd8+33fa3JrqaQSN3CP2whO4ozgZ56aZpUPRmWHu6aRqU9fEbcUQ3SYOCK1pOoJuoQV1/AqOiqxuEUTsEe9B1gHfpJmmQuc7oie7AoFG/QQ970OqGWUu6SRqUgKdlsK4R3bkaVFaycD0juokaZH4UMmsa7It79Wdag/KLu42+mm9ySF/vn2DQmB2CPdAPvfTTrsj9oOziLtkgZ5+T8e10AnugJ4raoNgdxQ1WqQY9VPt4jO8pIuyBrUFZ7K790/LVWRpU9EGb+HRRXfafpUE0indcRUV0xwaNd68cnJas7SLOszXokKXplmttu6V+8ntBwB7QNLnrb3YS3RQNyqjj3XRca090EzQot51zwxxnf8oiztKgsb7hC/Pp3C1rejZ/wiJO16BRvtkC8+lcgTVcapyyBK8yaKSv/sB8tlie2S4W0Z2rQZ1r0Bhf3ID5bGfQSYs4K4OMQ+hD9EsC5rOlQacs4nQMGuWaYJjPFjdTU+jCBo1vRSeGoAsZpB3qN7/hgSHoggaN8DE0hqBrMmhsDmEIurBB43MIQ9A1GDS6B/UYgq7ZoHE5hCHomgzaj8wh9MMSv6Nov+gqtK3Flg0MQddk0IO98fEwjgszDEEXN2g8txcxBF3EoLIO9Zz5IMAQdFGDRnR7EUPQxQ2iZtZz5oMAQ9C1MMg4NIbxHkPQtTFoLBYhKXaXxz7HX0bhEFIid3rs4/uylT9rRELcjjftvV+MRZLHfCTE7fjYJ/BlW3iUouQFgYS4Q9SgB8cjkf0RUiJ3fOzT9GW7FeoSkmJ3fOzT/AVbF51K1SMwBN1pBh1WJRlWYQi6LgYVX459YjINpyVLXqN4+peIVel4EYMOWQ7uKA6N0Rk0YYBbgHQgKXYv79aPC0iJHL9YnR6QELfFpUZBKhrDGdR2mVUTaTiIP6Rz9PY16JQg/pDu0eMXq1HScBB/SA/RoxerUdJwEH9IH9E7k4aD+EP6iN6ZNBzEH9JH9M6k4SD+kD6idyYNB/GH9BG9M2k4iD+kj+jnB3ALkA5wC5AOcAuQDnALkA5wC5AOcAuQDnALkA5wC5AOcAuQDnALkA5wC5AOcAuQDvTOmDdtY/X0B+/TEPNA0n+be9NE599wjW4Me/cgeVoGAoJAUuwW0PvI5KEi7dbex0XPtyrBxqtcLyMJ0uX+m+NPvw85mqv4ib/7gJTILUCPhgJbyOSBh9a0J49vSY3ZdSW0k7PZOtSXTeihHYlL++UQJMRtg3BZzcOipgeOwYoSMmhz/Y3XoE2oioSrVhhITtEM0hD0ocmg4Kb6G79zKit/H5T9MdCj5Zc/rVN/qxlJseOgahDuNcIGhR5G5oEi6fbiNYg2nPXt2rvRLTxx63WkRG6Bkw3Kw6OL/7eVI9uG+nKiqpj2805IiNsGpzaxxofZPr9NRg0G+TZjo66xeZu2QyAhbhs0ddL7sEHNu+95C1ssZgkV1tchU+5pXTUS4rZB4zAfNCi4gyxZE6x33hoUTkPrd3ibWPNEMSDuaRmsP9oCZ9mNJ9RzVv97vFurbxrZvEBK5FZovDbwG1Q0F2+yrKEZhfqgcJo8eEkTApJinyHALUA6wC1AOsAtQDrALUA6wC1AOsAtQDrALUA6wC1AOsAtQDrALUA6wC1AOsAtQDrALUA6wC1AOsAtQDrALUA6wC1AOsAtQDrALUA6wC1AOsAtQDrALUA6wC1AOsAtQDrALUA6wC1AOsAtoEB4vUMIzlYrOn3Kmp8UYCDeVKQbVEPdrT6BgXhTMRuksHv9Xq+iLBan7NZ/X9MqFb1g5r02qFic8rTUISu9Kt4Uu1gRpWLYpJroJ+MJndFRrx/NMprVntbTx3/Uux3QD00rFMtPF7SacrfWy+t1qfVier04KFeF0uvgn5Zm4b06TUv5aF1qdv1YJTUr5t+5ZO/oQK/FMobmPTmEXljawSyb372+ozphvqkDqh/ZxR0t/VIVxSw4Kz7o94OVTyp6Pan2xDlTnNVLtNLW2EWA/qiiKDuKHKAy6Q8qjvFFB1vLqg9KWHRStaR1MoqhkgTeCDkN6I0pDiqS6igu/7usSrmpG6TOHBmkW1JGfUwtaZ0sL9e9mpeHRtkHuQVPqEHmHYJ3x0nrZ+oDYdZtWCyBXljawZTL+JE77aRYWV3rgw4N2q3/onvyw6T1M/Whvq+BH72wtENZg3ZrNRqXpdyYAaw2ih0apEbzhS+pc2ZVvGmgao6pSh0nViXQC0s7lH3QxZ0qRq0jOZgHHRmUI5xUn1EOFvMgqlNNS5HTgH5opgtwC5AOcAuQDnALkA5wC5AOcAuQDnALkA5wC5AOcAuQDnALkA5wC5AOcAuQDnALkA5wC5AOcAuQDnALkA5wC5AOcAuQDnALkA5wC5AOcAuQDnALkA5wC5AOcAuQjt8A5+FVUSFBsRwAAAAASUVORK5CYII=" /><!-- --></p>
<p><strong>The histogram and density plot above suggests that the empirical and theoretical distributions approximately agree.</strong></p>
<hr />
</div>
</div>
<div id="exercise-5.1" class="section level2">
<h2>Exercise 5.1</h2>
<div id="question-5" class="section level3">
<h3>Question</h3>
<p><strong>To compute a Monte Carlo estimate <span class="math inline">\(\hat{\theta}\)</span> of <span class="math inline">\(\theta=\int_{0}^{\pi / 3} \sin t d t\)</span>, we creat function Monte_carlo, the parameter of this function is n, which represents the number of replicates. we notice that <span class="math inline">\(\theta=\frac{\pi}{3}*E(\sin X)\ \ X \sim \mathrm{U}[0,\pi/3]\)</span>, so that we use sample mean to estimate the mean of the population.</strong></p>
</div>
<div id="answer-7" class="section level3">
<h3>Answer</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Monte_carlo &lt;-<span class="st"> </span><span class="cf">function</span>(n) {
  <span class="kw">set.seed</span>(<span class="dv">12306</span>)
  <span class="co"># generate n random number from distribution U[0,pi/3]</span>
  r &lt;-<span class="st"> </span><span class="kw">runif</span>(n, <span class="dt">min =</span> <span class="dv">0</span>, <span class="dt">max =</span> pi <span class="op">/</span><span class="st"> </span><span class="dv">3</span>)
  <span class="co"># use the sample mean to estimate the population mean</span>
  MC_value &lt;-<span class="st"> </span>pi <span class="op">/</span><span class="st"> </span><span class="dv">3</span> <span class="op">*</span><span class="st"> </span><span class="kw">mean</span>(<span class="kw">sin</span>(r))
  <span class="co"># calcullate the true value use function: integrate</span>
  true_value &lt;-<span class="st"> </span><span class="dv">0</span> <span class="op">+</span><span class="st"> </span><span class="kw">integrate</span>(sin, <span class="dv">0</span>, pi <span class="op">/</span><span class="st"> </span><span class="dv">3</span>)<span class="op">$</span>value
  <span class="kw">return</span>(<span class="kw">c</span>(MC_value, true_value))
}
<span class="co"># simulation</span>
<span class="co">#Use x to represent our result</span>
x &lt;-<span class="st"> </span><span class="kw">Monte_carlo</span>(<span class="dv">1000000</span>)
<span class="kw">names</span>(x) &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="st">&quot;MC-estimate&quot;</span>, <span class="st">&quot;true-value&quot;</span>)
knitr<span class="op">::</span><span class="kw">kable</span>(x)</code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left"></th>
<th align="right">x</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">MC-estimate</td>
<td align="right">0.4997736</td>
</tr>
<tr class="even">
<td align="left">true-value</td>
<td align="right">0.5000000</td>
</tr>
</tbody>
</table>
<p><strong>From the above table, the estimated value is very close to the true value.</strong></p>
<hr />
</div>
</div>
<div id="exercise-5.7" class="section level2">
<h2>Exercise 5.7</h2>
<div id="question-6" class="section level3">
<h3>Question</h3>
<p><strong>Use a Monte Carlo simulation to estimate <span class="math inline">\(\theta\)</span> by the antithetic variate approach and by the simple Monte Carlo method. Compute an empirical estimate of the percent reduction in variance using the antithetic variate.Compare the result with the theoretical value.</strong></p>
</div>
<div id="answer-8" class="section level3">
<h3>Answer</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">12306</span>)
MC.Phi &lt;-<span class="st"> </span><span class="cf">function</span>(n, <span class="dt">R =</span> <span class="dv">10000</span>, <span class="dt">antithetic =</span> <span class="ot">TRUE</span>) {
t &lt;-<span class="st"> </span><span class="ot">NULL</span> 
<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n) {
  u &lt;-<span class="st"> </span><span class="kw">runif</span>(R <span class="op">/</span><span class="st"> </span><span class="dv">2</span>)
  <span class="cf">if</span> (<span class="op">!</span>antithetic)
    v &lt;-<span class="st"> </span><span class="kw">runif</span>(R <span class="op">/</span><span class="st"> </span><span class="dv">2</span>)
  <span class="cf">else</span>
    v &lt;-<span class="st"> </span><span class="dv">1</span> <span class="op">-</span><span class="st"> </span>u
  u &lt;-<span class="st"> </span><span class="kw">c</span>(u, v)
  t &lt;-<span class="st"> </span><span class="kw">c</span>(t, <span class="kw">mean</span>(<span class="kw">exp</span>(u)))
}
  t
}
<span class="co"># simulation</span>
n &lt;-<span class="st"> </span><span class="dv">100</span>
MC1 &lt;-<span class="st"> </span><span class="kw">MC.Phi</span>(n, <span class="dt">anti =</span> <span class="ot">FALSE</span>)
MC2 &lt;-<span class="st"> </span><span class="kw">MC.Phi</span>(n, <span class="dt">anti =</span> <span class="ot">TRUE</span>)
x &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="kw">mean</span>(MC1), <span class="kw">mean</span>(MC2), <span class="kw">exp</span>(<span class="dv">1</span>) <span class="op">-</span><span class="st"> </span><span class="dv">1</span>)
<span class="kw">names</span>(x) &lt;-
<span class="st">  </span><span class="kw">c</span>(<span class="st">&quot;simple Monte Carlo method&quot;</span>,
    <span class="st">&quot;antithetic variate approach&quot;</span>,
    <span class="st">&quot;true-value&quot;</span>)
knitr<span class="op">::</span><span class="kw">kable</span>(x)</code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left"></th>
<th align="right">x</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">simple Monte Carlo method</td>
<td align="right">1.717841</td>
</tr>
<tr class="even">
<td align="left">antithetic variate approach</td>
<td align="right">1.718323</td>
</tr>
<tr class="odd">
<td align="left">true-value</td>
<td align="right">1.718282</td>
</tr>
</tbody>
</table>
<p><strong>Both methods have good performance in estimating statistics, and the antithetic variate approach is better.</strong></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">print</span>((<span class="kw">var</span>(MC1) <span class="op">-</span><span class="st"> </span><span class="kw">var</span>(MC2))<span class="op">/</span><span class="kw">var</span>(MC1))</code></pre></div>
<pre><code>## [1] 0.9688039</code></pre>
<p><strong>An empirical estimate of the percent reduction in variance is 97.7242%.</strong></p>
<p><strong>Next we calculate the theoretical percent reduction in variance simply.</strong></p>
<span class="math display">\[\begin{equation}\nonumber\begin{aligned}
Var(e^{U}+e^{1-U}) &amp;= Var(e^{U})+2Cov(e^{U},e^{1-U})+ Var(e^{1-U})\\
&amp;=2 Var(e^{U})+2Cov(e^{U},e^{1-U})\\
&amp;=2E(e^{2U})-2E(e^{U})^{2}+2e-2E(e^{U})E(e^{1-U})\\
&amp;=e^{2}-1-2(e-1)^{2}+2(e-(e-1)^{2})\\
&amp; \dot{=} 0.01564999\end{aligned}\end{equation}\]</span>
<p><span class="math display">\[ \dfrac{4Var(e^{U})-Var(e^{U}+e^{1-U})}{4Var(e^{U})}*100\%
\dot{=}\dfrac{(4*0.2420356-0.0156499)}{4*0.2420356}=98.3835\%\]</span></p>
<p><strong>The theoretical percent reduction in variance is 98.3835%.</strong></p>
<p><strong>We can see that the empirical value is slightly smaller than the theoretical value, which may be caused by occasional fluctuations.</strong></p>
<hr />
</div>
</div>
<div id="exercise-5.11" class="section level2">
<h2>Exercise 5.11</h2>
<div id="question-7" class="section level3">
<h3>Question</h3>
<p><strong>Derive <span class="math inline">\(c^{*}\)</span> for the general case. That is, if <span class="math inline">\(\hat{\theta}_{1}\)</span> and <span class="math inline">\(\hat{\theta}_{2}\)</span> are any two unbiased estimators of <span class="math inline">\(\theta\)</span>, find the value <span class="math inline">\(c^{*}\)</span> that minimizes the variance of the estimator<span class="math inline">\(\hat{\theta}_{c}=c\hat{\theta}_{1}+(1-c)\hat{\theta}_{2}.\)</span> </strong></p>
</div>
<div id="answer-9" class="section level3">
<h3>Answer</h3>
<p><strong>Expand the variance of the estimator<span class="math inline">\(\hat{\theta}_{c}\)</span> directly.</strong></p>
<span class="math display">\[\begin{equation}\nonumber\begin{aligned}
Var(\hat{\theta}_{c})&amp;=c^{2}Var(\hat{\theta}_{1})+2c(1-c)Cov(\hat{\theta}_{1},\hat{\theta}_{2})+(1-c)^{2}Var(\hat{\theta}_{2})\\&amp;=Var(\hat{\theta}_{1}-\hat{\theta}_{2})c^{2}+2(Cov(\hat{\theta}_{1},\hat{\theta}_{2})-Var(\hat{\theta}_{2}))c+Var(\hat{\theta}_{2})\end{aligned}\end{equation}\]</span>
<p><strong>According to the property of the quadratic function,if and only if <span class="math display">\[c^{*}=\dfrac{Var(\hat{\theta}_{2})-Cov(\hat{\theta}_{1},\hat{\theta}_{2})}{Var(\hat{\theta}_{1}-\hat{\theta}_{2})},\]</span> the variance of the estimator <span class="math inline">\(\hat{\theta}_{c}\)</span> is the smallest.And after inspection, the value of c is within the defined domain.</strong></p>
<hr />
</div>
</div>
<div id="exercise-5.13" class="section level2">
<h2>Exercise 5.13</h2>
<div id="question-8" class="section level3">
<h3>Question</h3>
<p><strong>Find two importance functions <span class="math inline">\(f_1\)</span> and <span class="math inline">\(f_2\)</span> that are supported on <span class="math inline">\((1,\infty)\)</span> and are close to <span class="math inline">\(g(x) = \frac{x^2}{\sqrt{2 \pi}}e^{-x^2/2},x &gt; 1.\)</span></strong></p>
<p><strong>Which of your two importance functions should produce the smaller variance in estimating <span class="math inline">\(\int_{1}^{\infty}\frac{x^2}{\sqrt{2 \pi}}e^{-x^2/2}dx\)</span> by importance sampling? Explain. </strong></p>
</div>
<div id="answer-10" class="section level3">
<h3>Answer</h3>
<p><strong><span class="math inline">\(\theta=\int g(x)dx\)</span> can be written as <span class="math inline">\(\int \frac{g(x)}{f(x)}f(x)dx=E(g(X)/f(X)),\)</span>where <span class="math inline">\(X\)</span> has pdf/pmf <span class="math inline">\(f(\cdot)\)</span>. </strong></p>
<p><strong><span class="math inline">\(f(\cdot)\)</span> is a pdf/pmf from which random samples are easy to generate, which is called the importance function of <span class="math inline">\(g(\cdot)\)</span>.</strong></p>
<p><strong><span class="math inline">\(\theta\)</span> can be estimated by<span class="math display">\[\hat\theta=\frac1m\sum_{i=1}^m\frac{g(X_i)}{f(X_i)}.\]</span></strong></p>
<p><strong>The variance of <span class="math inline">\(\hat\theta\)</span> is <span class="math inline">\(var(g(X_1)/f(X_1))/m\)</span>, which has the minimal value 0 when <span class="math inline">\(g(\cdot) = c f(\cdot)\)</span> for some constant <span class="math inline">\(c\)</span>.</strong></p>
<p><strong>We select <span class="math inline">\(f_1=e^{-x+1}, x&gt;1\)</span> and <span class="math inline">\(f_2=\frac{1}{2}{(x-1)}^2e^{-x+1}, x&gt;1\)</span>.</strong></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">12306</span>)
x &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="dv">1</span>,<span class="dv">5</span>,<span class="dt">length.out =</span> <span class="dv">20</span>)
    g &lt;-<span class="st"> </span><span class="kw">exp</span>(<span class="op">-</span>x<span class="op">^</span><span class="dv">2</span><span class="op">/</span><span class="dv">2</span>)<span class="op">*</span>x<span class="op">^</span><span class="dv">2</span><span class="op">/</span><span class="kw">sqrt</span>(<span class="dv">2</span><span class="op">*</span>pi)
    f1 &lt;-<span class="st"> </span><span class="kw">exp</span>(<span class="op">-</span>x<span class="op">+</span><span class="dv">1</span>)
    f2 &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">/</span><span class="dv">2</span><span class="op">*</span>(x<span class="op">-</span><span class="dv">1</span>)<span class="op">^</span><span class="dv">2</span> <span class="op">*</span><span class="kw">exp</span>(<span class="op">-</span>x<span class="op">+</span><span class="dv">1</span>)
<span class="co">#figure (a)</span>
<span class="kw">plot</span>(f1<span class="op">~</span>x,<span class="dt">type =</span> <span class="st">&quot;l&quot;</span>,<span class="dt">col=</span><span class="dv">2</span>,<span class="dt">lty=</span><span class="dv">2</span>,<span class="dt">main=</span><span class="st">&quot;figure (a)&quot;</span>)
<span class="kw">lines</span>(g<span class="op">~</span>x,<span class="dt">col=</span><span class="dv">1</span>,<span class="dt">lty=</span><span class="dv">1</span>)
<span class="kw">lines</span>(f2<span class="op">~</span>x,<span class="dt">col=</span><span class="dv">3</span>,<span class="dt">lty=</span><span class="dv">3</span>)
<span class="kw">legend</span>(<span class="st">&quot;topright&quot;</span>, <span class="dt">legend =</span><span class="kw">c</span>(<span class="st">&quot;g&quot;</span>, <span class="st">&quot;f1&quot;</span>, <span class="st">&quot;f2&quot;</span>),
           <span class="dt">lty =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">3</span>, <span class="dt">lwd =</span> <span class="dv">2</span>, <span class="dt">inset =</span> <span class="fl">0.02</span>,<span class="dt">col=</span><span class="dv">1</span><span class="op">:</span><span class="dv">3</span>)</code></pre></div>
<p><img src="data:image/png;base64,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" /><!-- --></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co">#figure (b)</span>
<span class="kw">plot</span>(g<span class="op">/</span>f2<span class="op">~</span>x,<span class="dt">type =</span> <span class="st">&quot;l&quot;</span>,<span class="dt">col=</span><span class="dv">2</span>,<span class="dt">main=</span><span class="st">&quot;figure (b)&quot;</span>)
<span class="kw">lines</span>(g<span class="op">/</span>f1<span class="op">~</span>x,<span class="dt">col=</span><span class="dv">1</span>)
<span class="kw">legend</span>(<span class="st">&quot;topright&quot;</span>, <span class="dt">legend =</span><span class="kw">c</span>(<span class="st">&quot;g/f1&quot;</span>, <span class="st">&quot;g/f2&quot;</span>),
           <span class="dt">lty =</span> <span class="dv">1</span><span class="op">:</span><span class="dv">2</span>, <span class="dt">lwd =</span> <span class="dv">2</span>, <span class="dt">inset =</span> <span class="fl">0.02</span>,<span class="dt">col=</span><span class="dv">1</span><span class="op">:</span><span class="dv">2</span>)</code></pre></div>
<p><img src="data:image/png;base64,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" /><!-- --></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">m &lt;-<span class="st"> </span><span class="dv">10000</span>
  theta.hat &lt;-<span class="st"> </span>se &lt;-<span class="st"> </span><span class="kw">numeric</span>(<span class="dv">2</span>)
  g &lt;-<span class="st"> </span><span class="cf">function</span>(x) <span class="kw">exp</span>(<span class="op">-</span>x<span class="op">^</span><span class="dv">2</span><span class="op">/</span><span class="dv">2</span>)<span class="op">*</span>x<span class="op">^</span><span class="dv">2</span><span class="op">/</span><span class="kw">sqrt</span>(<span class="dv">2</span><span class="op">*</span>pi) <span class="op">*</span><span class="st"> </span>(x <span class="op">&gt;</span><span class="st"> </span><span class="dv">1</span>)
x &lt;-<span class="st"> </span><span class="kw">rexp</span>(m, <span class="dt">rate=</span> <span class="dv">1</span>)<span class="op">+</span><span class="dv">1</span> <span class="co">#using f1</span>
  fg &lt;-<span class="st"> </span><span class="kw">g</span>(x)<span class="op">/</span><span class="kw">exp</span>(<span class="op">-</span>x<span class="op">+</span><span class="dv">1</span>)
  theta.hat[<span class="dv">1</span>] &lt;-<span class="st"> </span><span class="kw">mean</span>(fg)
  se[<span class="dv">1</span>] &lt;-<span class="st"> </span><span class="kw">sd</span>(fg)
x &lt;-<span class="st"> </span><span class="kw">rgamma</span>(m, <span class="dt">shape=</span><span class="dv">3</span>, <span class="dt">rate =</span> <span class="dv">1</span>)<span class="op">+</span><span class="dv">1</span> <span class="co">#using f2</span>
  fg &lt;-<span class="st"> </span><span class="kw">g</span>(x)<span class="op">/</span>(<span class="dv">1</span><span class="op">/</span><span class="dv">2</span><span class="op">*</span>(x<span class="op">-</span><span class="dv">1</span>)<span class="op">^</span><span class="dv">2</span> <span class="op">*</span><span class="kw">exp</span>(<span class="op">-</span>x<span class="op">+</span><span class="dv">1</span>))
  theta.hat[<span class="dv">2</span>] &lt;-<span class="st"> </span><span class="kw">mean</span>(fg)
  se[<span class="dv">2</span>] &lt;-<span class="st"> </span><span class="kw">sd</span>(fg)
  res &lt;-<span class="st"> </span><span class="kw">rbind</span>(<span class="dt">theta=</span><span class="kw">round</span>(theta.hat,<span class="dv">3</span>), <span class="dt">se=</span><span class="kw">round</span>(se,<span class="dv">3</span>))
  <span class="kw">colnames</span>(res) &lt;-<span class="st"> </span><span class="kw">paste0</span>(<span class="st">'f'</span>,<span class="dv">1</span><span class="op">:</span><span class="dv">2</span>)
  knitr<span class="op">::</span><span class="kw">kable</span>(res,<span class="dt">align=</span><span class="st">'c'</span>)</code></pre></div>
<table>
<thead>
<tr class="header">
<th align="left"></th>
<th align="center">f1</th>
<th align="center">f2</th>
</tr>
</thead>
<tbody>
<tr class="odd">
<td align="left">theta</td>
<td align="center">0.399</td>
<td align="center">0.393</td>
</tr>
<tr class="even">
<td align="left">se</td>
<td align="center">0.160</td>
<td align="center">1.597</td>
</tr>
</tbody>
</table>
<p><strong>From the figure and table, we can see <span class="math inline">\(f_1\)</span> produces the smaller variance in estimating.The reason for this phenomenon may be that g is closer to f1,which can be seen in figure (b). Close here refers to the tendency to be a constant after division.</strong></p>
<hr />
</div>
</div>
<div id="exercise-5.15" class="section level2">
<h2>Exercise 5.15</h2>
<div id="question-9" class="section level3">
<h3>Question</h3>
<p><strong>Obtain the stratified importance sampling estimate in Example 5.13 and compare it with the result of Example 5.10.</strong></p>
</div>
<div id="answer-11" class="section level3">
<h3>Answer</h3>
<p><strong>We use Stratified Importance sampling to estimate <span class="math inline">\(\int_{0}^{1} \frac{e^{-x}}{1+x^{2}} dx.\)</span> </strong></p>
<p><strong>firstly, we divide the interval <span class="math inline">\([0,1]\)</span> into five subintervals by the four fifth-quanliles of the population:<span class="math display">\[\mathrm{F}(\mathrm{x})=\frac{1-e^{-x}}{1-e^{-1}} \quad 0 \leq x \leq 1.\]</span></strong></p>
<p><strong>quantis the result, with its first number 0 and last number 1, then in each subinterval, the sampling function which also represents the density function of the random variable in each interval changes to <span class="math display">\[\frac{5e^{-x}}{1-e^{-1}}\]</span></strong></p>
<p><strong>At the same time, the expectation we want to calculate in each subinterval is<span class="math display">\[\mathrm{E}\left(\frac{1-e^{-1}}{5\left(1+X^{2}\right)}\right)\]</span> to generate random number satisfing our demand, we use acceptance-rejection method, in each subinterval, we calculate the optimal c, for g, we specified it to be the density function of uniform distridution in each subinterval, and due to the whole number of replicates is 10000, in each subinterval, we generate 2000 random numbers. we repeat the estimate 100 times and use the sample standard deviation to estimate standard deviation of population.</strong></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">F&lt;-<span class="cf">function</span>(x) <span class="kw">return</span>((<span class="dv">1</span><span class="op">-</span><span class="kw">exp</span>(<span class="op">-</span>x))<span class="op">/</span>(<span class="dv">1</span><span class="op">-</span><span class="kw">exp</span>(<span class="op">-</span><span class="dv">1</span>))) <span class="co"># distribution function</span>
F_inverse&lt;-<span class="cf">function</span>(x) <span class="kw">return</span>(<span class="op">-</span><span class="kw">log</span>(<span class="dv">1</span><span class="op">-</span>(<span class="dv">1</span><span class="op">-</span><span class="kw">exp</span>(<span class="op">-</span><span class="dv">1</span>))<span class="op">*</span>x)) <span class="co"># the inverse function of distribution function</span>
G&lt;-<span class="cf">function</span>(x) <span class="kw">return</span>((<span class="dv">1</span><span class="op">-</span><span class="kw">exp</span>(<span class="op">-</span><span class="dv">1</span>))<span class="op">/</span>(<span class="dv">5</span><span class="op">*</span>(<span class="dv">1</span><span class="op">+</span>x<span class="op">^</span><span class="dv">2</span>))) <span class="co"># the function of the random variable, we want to calculate its expectation</span>
f&lt;-<span class="cf">function</span>(x) <span class="kw">return</span>(<span class="dv">5</span><span class="op">*</span><span class="kw">exp</span>(<span class="op">-</span>x)<span class="op">/</span>(<span class="dv">1</span><span class="op">-</span><span class="kw">exp</span>(<span class="op">-</span><span class="dv">1</span>))) <span class="co"># density function of random variable in each subinterval</span>

quant&lt;-<span class="kw">F_inverse</span>(<span class="kw">seq</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dt">by=</span><span class="dv">1</span><span class="op">/</span><span class="dv">5</span>)) <span class="co"># interval endpoints of the 5 subintervals</span>
g&lt;-(quant[<span class="op">-</span><span class="dv">1</span>]<span class="op">-</span>quant[<span class="op">-</span><span class="dv">6</span>])<span class="op">^-</span><span class="dv">1</span> <span class="co"># the density function of uniform distridution in each subinterval</span>
theta_hat&lt;-<span class="kw">numeric</span>(<span class="dv">100</span>)
<span class="cf">for</span>(k <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">100</span>){
theta&lt;-<span class="kw">numeric</span>(<span class="dv">5</span>)
<span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="dv">5</span>){
  <span class="co"># use acceptance-rejection method to generate the random number</span>
 
  random_vector&lt;-<span class="kw">numeric</span>(<span class="dv">0</span>)
  
  c&lt;-<span class="kw">f</span>(quant[i])<span class="op">/</span>g[i]
  <span class="cf">while</span> (<span class="kw">length</span>(random_vector)<span class="op">&lt;</span><span class="dv">2000</span>) {
    Y&lt;-<span class="kw">runif</span>(<span class="dv">1</span>,<span class="dt">min=</span>quant[i],<span class="dt">max=</span>quant[i<span class="op">+</span><span class="dv">1</span>])
    U&lt;-<span class="kw">runif</span>(<span class="dv">1</span>)
    <span class="cf">if</span>(U<span class="op">&lt;</span>(<span class="kw">f</span>(Y)<span class="op">/</span>(c<span class="op">*</span>g[i]))) random_vector&lt;-<span class="kw">c</span>(random_vector,Y)
  }
  
  theta[i]&lt;-<span class="kw">mean</span>(<span class="kw">G</span>(random_vector))
  
}


theta_hat[k]&lt;-<span class="kw">sum</span>(theta)
}
<span class="kw">list</span>(<span class="dt">theta_hat=</span>theta_hat,<span class="dt">sd=</span><span class="kw">sd</span>(theta_hat))</code></pre></div>
<pre><code>## $theta_hat
##   [1] 0.5247356 0.5250882 0.5247299 0.5250999 0.5247785 0.5246377 0.5249149
##   [8] 0.5246278 0.5245818 0.5252350 0.5249159 0.5251021 0.5247148 0.5251480
##  [15] 0.5251282 0.5246576 0.5248518 0.5248425 0.5249873 0.5249769 0.5249622
##  [22] 0.5247456 0.5247279 0.5246887 0.5248385 0.5251818 0.5245312 0.5248879
##  [29] 0.5245931 0.5248613 0.5245420 0.5249409 0.5243735 0.5250682 0.5245087
##  [36] 0.5248993 0.5247862 0.5245696 0.5247082 0.5248938 0.5243725 0.5248981
##  [43] 0.5247097 0.5245131 0.5247468 0.5243359 0.5250425 0.5242575 0.5249861
##  [50] 0.5248259 0.5245363 0.5250890 0.5248053 0.5243560 0.5246672 0.5249765
##  [57] 0.5245785 0.5247853 0.5247111 0.5250157 0.5247873 0.5246988 0.5246238
##  [64] 0.5245907 0.5249643 0.5245592 0.5250348 0.5246996 0.5249672 0.5249873
##  [71] 0.5244363 0.5247858 0.5248073 0.5252448 0.5248319 0.5247823 0.5249720
##  [78] 0.5246828 0.5249327 0.5250484 0.5249533 0.5250339 0.5251086 0.5245932
##  [85] 0.5246820 0.5248395 0.5247227 0.5248308 0.5250962 0.5247798 0.5245327
##  [92] 0.5245860 0.5244617 0.5249252 0.5249726 0.5245349 0.5253005 0.5250759
##  [99] 0.5250284 0.5242730
## 
## $sd
## [1] 0.0002296719</code></pre>
<p><strong>from the result we can figure out that importance sampling with stratified has a prominent standard deviation reduction in contrast with the one without stratified, the original standard deviation is 0.0970314, meanwhile, the estimation becomes more accurate.</strong></p>
<hr />
</div>
</div>
<div id="exercise-6.4" class="section level2">
<h2>Exercise 6.4</h2>
<div id="question-10" class="section level3">
<h3>Question</h3>
<p><strong>Suppose that <span class="math inline">\(X_{1},X_{2}...X_{n}\)</span> are a random sample from a lognormal distribution with unknown parameters. Construct a 95% confidence interval for the parameter <span class="math inline">\(\mu\)</span>. Use a Monte Carlo method to obtain an empirical estimate of the confidence level. </strong></p>
</div>
<div id="answer-12" class="section level3">
<h3>Answer</h3>
<p><strong>The density function of the lognormal distribution is <span class="math display">\[f(x;\mu,\sigma)=\frac{1}{\sqrt{2\pi}x\sigma}e^{\dfrac{-(lnx-\mu)^{2}}{2\sigma^{2}}}\]</span>.</strong></p>
<p><strong>The maximum likelihood estimate of the lognormal distribution is<span class="math display">\[\hat{\mu}=\frac{1}{n}\sum_{i=1}^{n}ln(X_{i}),\]</span> <span class="math display">\[\hat{\sigma^{2}}=\frac{1}{n}\sum_{i=1}^{n}(ln(X_{i})-\hat{\mu}).\]</span></strong></p>
<p><strong>According to the sampling distribution theorem of the normal case and ln(X) is a normal distribution,we have <span class="math display">\[\hat{\mu}\to N(\mu,\frac{1}{n}\sigma^{2}),\]</span> <span class="math display">\[\dfrac{n\hat{\sigma^{2}}}{\sigma^{2}}\to \chi^{2}(n-1)\]</span>.And these two are independent of each other.</strong></p>
<p><strong>So <span class="math display">\[\dfrac{\hat{\mu}-\mu}{\hat{\sigma^{2}}/\sqrt{n-1}}\to t(n-1).\]</span></strong></p>
<p><strong>Then when <span class="math inline">\(\mu\)</span> and <span class="math inline">\(\sigma\)</span> are unknown,we have the interval estimate of <span class="math inline">\(\mu\)</span>:<span class="math display">\[(\hat{\mu}-\frac{\hat{\sigma^{2}}}{\sqrt{n-1}}t_{\alpha/2}(n-1),\hat{\mu}+\frac{\hat{\sigma^{2}}}{\sqrt{n-1}}t_{\alpha/2}(n-1)),\]</span> where <span class="math inline">\(\hat{\mu}=\frac{1}{n}\sum_{i=1}^{n}ln(X_{i})\)</span>, <span class="math inline">\(\hat{\sigma^{2}}=\frac{1}{n}\sum_{i=1}^{n}(ln(X_{i})-\hat{\mu})\)</span> and <span class="math inline">\(\alpha=0.05\)</span>.</strong></p>
<p><strong>Use Monte Carlo method to obtain an empirical estimate of the confidence level:Repeat m times(big enough) to draw samples with the sample size of n from the distribution of <span class="math inline">\(f(x;\mu,\sigma)\)</span>.Then use the following formula to calculate ECP. <span class="math display">\[ECP=\frac{1}{m}\sum_{i=1}^{m}I(\hat{\mu}-\frac{\hat{\sigma^{2}}}{\sqrt{n-1}}t_{\alpha/2}(n-1)&lt;\mu&lt;\hat{\mu}+\frac{\hat{\sigma^{2}}}{\sqrt{n-1}}t_{\alpha/2}(n-1))).\]</span></strong></p>
<hr />
</div>
</div>
<div id="exercise-6.5" class="section level2">
<h2>Exercise 6.5</h2>
<div id="question-11" class="section level3">
<h3>Question</h3>
<p><strong>Use a Monte Carlo experiment to estimate the coverage probability of the t-interval for random samples of <span class="math inline">\(\chi_{2}(2)\)</span> data with sample size n = 20. Compare your t-interval results with the simulation results in Example 6.4.</strong></p>
</div>
<div id="answer-13" class="section level3">
<h3>Answer</h3>
<div id="empirical-confidence-level-for-mean" class="section level4">
<h4>(1)empirical confidence level for mean</h4>
<p><strong>This question means that we should use a Monte Carlo experiment to estimate the coverage probability of the 95% symmetric t-interval for random samples of <span class="math inline">\(\chi^{2}(2)\)</span> data,to see the probability that the confidence interval covers the mean is higher or lower than 0.95.</strong></p>
<p><strong>Firstly according to the sampling distribution theorem, if the sample is normal distribution, then: <span class="math display">\[\frac{\hat{X}-\mu}{S / \sqrt{n}} \to t(n-1),\]</span>where <span class="math inline">\(\mu\)</span> is population mean, for <span class="math inline">\(\chi^{2}(2)\)</span>, it equals to 2, <span class="math inline">\(\hat{X}\)</span> is sample mean, <span class="math inline">\(S^{2}\)</span> is the sample variance, <span class="math inline">\(n\)</span> is the number of samples.</strong></p>
<p><strong>so the 95% symmetric t-interval for population mean <span class="math inline">\(\mu\)</span> is:<span class="math display">\[\left(\hat{X}-\frac{S}{\sqrt{n}}t_{\alpha/2}(n-1), \hat{X}-\frac{S}{\sqrt{n}} t_{\frac{a}{2}}(n-1)\right),\]</span></strong></p>
<p><strong>where <span class="math inline">\(\alpha\)</span> is the significance level, we creat function cpt to return the empirical confidence level for mean.</strong></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">cpt&lt;-<span class="cf">function</span>(m,<span class="dt">n=</span><span class="dv">20</span>,<span class="dt">alpha=</span><span class="fl">0.05</span>){
  <span class="co"># m: the number of random experiment</span>
  <span class="co"># n: the number of random numbers generated in each experiment</span>
  <span class="co"># alpha: the significance level.</span>
  <span class="co"># generate matrix of random numbers of dim m*n</span>
  chisq&lt;-<span class="kw">matrix</span>(<span class="kw">rchisq</span>(m<span class="op">*</span>n,<span class="dt">df=</span><span class="dv">2</span>),<span class="dt">nrow =</span> m,<span class="dt">ncol =</span> n)
  <span class="co"># calculate the symmetric t confidence interval according to each row of random numbers</span>
  interval_cal&lt;-<span class="cf">function</span>(x) <span class="kw">return</span>(<span class="kw">c</span>(<span class="kw">mean</span>(x)<span class="op">-</span><span class="kw">var</span>(x)<span class="op">/</span><span class="kw">sqrt</span>(n)<span class="op">*</span><span class="kw">qt</span>(<span class="dv">1</span><span class="op">-</span>alpha<span class="op">/</span><span class="dv">2</span>,<span class="dt">df=</span>n<span class="op">-</span><span class="dv">1</span>),
                                 <span class="kw">mean</span>(x)<span class="op">-</span><span class="kw">var</span>(x)<span class="op">/</span><span class="kw">sqrt</span>(n)<span class="op">*</span><span class="kw">qt</span>(alpha<span class="op">/</span><span class="dv">2</span>,<span class="dt">df=</span>n<span class="op">-</span><span class="dv">1</span>)))
  interval_matix&lt;-<span class="kw">t</span>(<span class="kw">apply</span>(chisq,<span class="dv">1</span>,interval_cal))
  <span class="co"># calculate the empirical confidence level</span>
  <span class="kw">return</span>(<span class="dv">1</span><span class="op">/</span>m<span class="op">*</span><span class="kw">sum</span>(<span class="dv">2</span><span class="op">&gt;</span><span class="st"> </span>interval_matix[,<span class="dv">1</span>]<span class="op">&amp;</span><span class="dv">2</span><span class="op">&lt;</span>interval_matix[,<span class="dv">2</span>]))
  
}
<span class="kw">cpt</span>(<span class="dt">m=</span><span class="dv">1000</span>)</code></pre></div>
<pre><code>## [1] 0.946</code></pre>
<p><strong>From the result, the empirical confidence level is close to 0.95, so that the interval estimation for mean is not sensitive to departures from normality.</strong></p>
</div>
<div id="empirical-confidence-level-for-variance" class="section level4">
<h4>(2)empirical confidence level for variance</h4>
<p><strong>In order to compared with example 6.4, we conduct 1000 random experiments too, and calculate empirical confidence intervals for variance:<span class="math display">\[\left(0,(n-1) S^{2} / \chi_{\alpha}^{2}\right)\]</span></strong></p>
<p><strong>For <span class="math inline">\(\chi^{2}(2)\)</span>, the variance is 4.</strong></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">upper_bound&lt;-<span class="kw">replicate</span>(<span class="dv">1000</span>,<span class="dt">expr=</span>{
  n&lt;-<span class="dv">20</span>
  alpha&lt;-<span class="fl">0.05</span>
  x &lt;-<span class="st"> </span><span class="kw">rchisq</span>(n, <span class="dt">df=</span><span class="dv">2</span>)
  (n<span class="op">-</span><span class="dv">1</span>) <span class="op">*</span><span class="st"> </span><span class="kw">var</span>(x) <span class="op">/</span><span class="st"> </span><span class="kw">qchisq</span>(alpha, <span class="dt">df =</span> n<span class="op">-</span><span class="dv">1</span>)
})
cpt_variance&lt;-<span class="kw">mean</span>(upper_bound<span class="op">&gt;</span><span class="dv">4</span>)

<span class="kw">cat</span>(<span class="st">'the empirical confidence level for variance is:'</span>, cpt_variance)</code></pre></div>
<pre><code>## the empirical confidence level for variance is: 0.781</code></pre>
<p><strong>From the result, we know that if the population don't obey normal istribution, the empirical confidence level for variance is far lower than 0.95, so that The t-interval is more robust to departures from normality than the interval for variance.</strong></p>
<hr />
</div>
</div>
</div>
<div id="exercise-6.7" class="section level2">
<h2>Exercise 6.7</h2>
<div id="question-12" class="section level3">
<h3>Question</h3>
<p><strong>Estimate the power of the skewness test of normality against symmetric <span class="math inline">\(Beta(\alpha,\alpha)\)</span> distributions and comment on the results. Are the results different for heavy-tailed symmetric alternatives such as <span class="math inline">\(t(\nu)\)</span>?</strong></p>
</div>
<div id="answer-14" class="section level3">
<h3>Answer</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">12306</span>)
<span class="kw">library</span>(knitr)
sig &lt;-<span class="fl">0.05</span> <span class="co"># significance level</span>
m &lt;-<span class="dv">1000</span> <span class="co"># times of simulations</span>
n &lt;-<span class="dv">500</span> <span class="co"># number of replications in each simulation</span>
cv &lt;-<span class="st"> </span><span class="kw">qnorm</span>(<span class="dv">1</span><span class="op">-</span>sig<span class="op">/</span><span class="dv">2</span>, <span class="dv">0</span>, <span class="kw">sqrt</span>(<span class="dv">6</span><span class="op">*</span>(n<span class="op">-</span><span class="dv">2</span>) <span class="op">/</span><span class="st"> </span>((n<span class="op">+</span><span class="dv">1</span>)<span class="op">*</span>(n<span class="op">+</span><span class="dv">3</span>))))

<span class="co"># sk is the fuction used to compute the sample skewness coeff.</span>

sk &lt;-<span class="st"> </span><span class="cf">function</span>(x) {
xbar &lt;-<span class="st"> </span><span class="kw">mean</span>(x)
m3 &lt;-<span class="st"> </span><span class="kw">mean</span>((x <span class="op">-</span><span class="st"> </span>xbar)<span class="op">^</span><span class="dv">3</span>)
m2 &lt;-<span class="st"> </span><span class="kw">mean</span>((x <span class="op">-</span><span class="st"> </span>xbar)<span class="op">^</span><span class="dv">2</span>)
<span class="kw">return</span>( m3 <span class="op">/</span><span class="st"> </span>m2<span class="op">^</span><span class="fl">1.5</span> )
}

alpha&lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="fl">0.5</span>,<span class="dv">10</span>,<span class="dt">by=</span><span class="fl">0.5</span>) <span class="co"># parameter of symmetric beta distribution</span>
power&lt;-<span class="kw">numeric</span>(<span class="kw">length</span>(alpha))

<span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(alpha)){
   reject_i&lt;-<span class="kw">replicate</span>(m,<span class="dt">expr=</span>{
   rand_num&lt;-<span class="kw">rbeta</span>(n,alpha[i],alpha[i])  
   skew&lt;-<span class="kw">sk</span>(rand_num) 
   <span class="kw">as.integer</span>(<span class="kw">abs</span>(skew)<span class="op">&gt;=</span>cv) 
     
   })
   
  power[i]&lt;-<span class="kw">mean</span>(reject_i)
}
<span class="kw">plot</span>(alpha ,power,<span class="dt">type=</span><span class="st">'l'</span>, <span class="dt">xlab=</span><span class="st">'alpha'</span>,<span class="dt">ylab=</span><span class="st">'power'</span>, <span class="dt">main=</span><span class="st">'power versus alpha for Beta(alpha,alpha)'</span>)</code></pre></div>
<p><img src="data:image/png;base64,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" /><!-- --></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">knitr<span class="op">::</span><span class="kw">kable</span> (<span class="kw">rbind</span>(alpha,power),<span class="dt">format =</span> <span class="st">'html'</span>,<span class="dt">row.names =</span> T,<span class="dt">digits =</span> <span class="dv">2</span>)</code></pre></div>
<table>
<tbody>
<tr>
<td style="text-align:left;">
alpha
</td>
<td style="text-align:right;">
0.5
</td>
<td style="text-align:right;">
1
</td>
<td style="text-align:right;">
1.5
</td>
<td style="text-align:right;">
2
</td>
<td style="text-align:right;">
2.5
</td>
<td style="text-align:right;">
3
</td>
<td style="text-align:right;">
3.5
</td>
<td style="text-align:right;">
4.00
</td>
<td style="text-align:right;">
4.50
</td>
<td style="text-align:right;">
5.00
</td>
<td style="text-align:right;">
5.50
</td>
<td style="text-align:right;">
6.00
</td>
<td style="text-align:right;">
6.50
</td>
<td style="text-align:right;">
7.00
</td>
<td style="text-align:right;">
7.50
</td>
<td style="text-align:right;">
8.00
</td>
<td style="text-align:right;">
8.50
</td>
<td style="text-align:right;">
9.00
</td>
<td style="text-align:right;">
9.50
</td>
<td style="text-align:right;">
10.00
</td>
</tr>
<tr>
<td style="text-align:left;">
power
</td>
<td style="text-align:right;">
0.0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0.0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0.0
</td>
<td style="text-align:right;">
0
</td>
<td style="text-align:right;">
0.0
</td>
<td style="text-align:right;">
0.01
</td>
<td style="text-align:right;">
0.01
</td>
<td style="text-align:right;">
0.01
</td>
<td style="text-align:right;">
0.01
</td>
<td style="text-align:right;">
0.01
</td>
<td style="text-align:right;">
0.01
</td>
<td style="text-align:right;">
0.01
</td>
<td style="text-align:right;">
0.01
</td>
<td style="text-align:right;">
0.01
</td>
<td style="text-align:right;">
0.01
</td>
<td style="text-align:right;">
0.02
</td>
<td style="text-align:right;">
0.01
</td>
<td style="text-align:right;">
0.02
</td>
</tr>
</tbody>
</table>
<p><strong>From the result above, we can know that the power is lower than 0.05, and it has an increasing trend as alpha increase but not strictly, this is because skewness test mainly test symmetrical features of a distribution and beta distribution has this features.</strong></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># the degree of freedom of the T distribution</span>
v&lt;-<span class="dv">1</span><span class="op">:</span><span class="dv">100</span>

m &lt;-<span class="dv">1000</span> <span class="co"># times of simulations</span>
n &lt;-<span class="dv">500</span> <span class="co"># number of replications in each simulation</span>
cv &lt;-<span class="st"> </span><span class="kw">qnorm</span>(<span class="dv">1</span><span class="op">-</span>sig<span class="op">/</span><span class="dv">2</span>, <span class="dv">0</span>, <span class="kw">sqrt</span>(<span class="dv">6</span><span class="op">*</span>(n<span class="op">-</span><span class="dv">2</span>) <span class="op">/</span><span class="st"> </span>((n<span class="op">+</span><span class="dv">1</span>)<span class="op">*</span>(n<span class="op">+</span><span class="dv">3</span>)))) <span class="co"># the critical value</span>

<span class="co"># store the power </span>
power_t&lt;-<span class="kw">numeric</span>(<span class="dv">100</span>)

<span class="cf">for</span>(j <span class="cf">in</span> v){

reject.t&lt;-<span class="st"> </span><span class="kw">vector</span>(<span class="st">'numeric'</span>,<span class="dt">length=</span>m)

<span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>m){
  rand_num&lt;-<span class="kw">rt</span>(n,<span class="dt">df=</span>j)
  skew&lt;-<span class="kw">sk</span>(rand_num)
  reject.t[i]&lt;-<span class="kw">as.integer</span>(<span class="kw">abs</span>(skew)<span class="op">&gt;=</span>cv)
}
power_t[j]&lt;-<span class="kw">mean</span>(reject.t)
}

<span class="kw">plot</span>(v,power_t,<span class="dt">xlab=</span><span class="st">'df'</span>,<span class="dt">ylab=</span><span class="st">'power'</span>,<span class="dt">type=</span><span class="st">'l'</span>,<span class="dt">main=</span><span class="st">' power versus v for t(v)'</span>)

<span class="kw">abline</span>(<span class="dt">h=</span><span class="fl">0.1</span>)</code></pre></div>
<p><img src="data:image/png;base64,iVBORw0KGgoAAAANSUhEUgAAASAAAAEgCAMAAAAjXV6yAAAApVBMVEUAAAAAADoAAGYAOjoAOmYAOpAAZmYAZrY6AAA6ADo6OgA6OmY6ZmY6ZpA6ZrY6kLY6kNtmAABmADpmOgBmOjpmkLZmkNtmtttmtv+QOgCQZgCQZjqQkDqQkGaQtpCQtv+Q27aQ2/+2ZgC2Zjq2ZpC227a229u22/+2/7a2/9u2///bkDrbkGbbtmbbtpDb29vb////tmb/25D/27b//7b//9v///8MGPTuAAAACXBIWXMAAA7DAAAOwwHHb6hkAAAJ1klEQVR4nO2d7WLbNABF1bIuYTBYGLBmY4N5jLKaQd0mef9HQ1+2ZVfyjWOrUZR7fnSZJUvysSTLiSyLHRlEHLsAqUNBAAoCUBCAggAUBKAgAAUBKAhAQQAKAlAQgIIAFASgIAAFASgIQEEACgJQEICCABQEoCAABQEoCEBBAAoCUBCAggAUBKAgAAUBMhS0/bQU4oeB8D9v5d/N6uKjs/F+eXnrjZ2hoEpIXgWDH15rFaW4unO2bteBXTIUVIpO3ehTCCXokZCesIaJgmRun38W4tmN/t+/8uM3v9ypzVf6r7jWJ/RaVnshLn64M8X/8Fpc3rRlNTF8Uf55ITe9vGliblb6qNrNjxLR/5coRU1penlKLm8rFcXd9X5p959bkEGfs9J8lm509vJw1PGoUqiPkme3dSRztuxBaZ2eKDY9dRCuIGdzPxFXUFuaTp5WUKn27+XvbWPTBckT81WIhernVEalsqJPh/wjN8u6vFDHd6P+bw7v6mb3n95bh9miPY4ity/uVNqvOoLczf1ENKaJOaXp5GmSMjt1di38bWy6oOs6U1th1T8651KfKuXKFkGftVI4VdluMdWtH0Xu+eyvJp9GkLu5l4gryClNN0+9RVnu7VoI73Vseh90a8skpVzd1eVTXV4hnstLaWkkNS2x04Uqe2Y/TxQZIOpexBHkbu4l4gjqlcbJUydlqmpn10DfPo8g1ZjtSTENW3ZCf6zEG3mpUDW3EgFBqqaZsvqiPLw2W36v8zFRnc29RBxBndIEBbm7RhX0qAbJ8n2/VNXn+aruktzi79r/Xf5WdxmeKA/vX5je1RXkbO4l4uy+Xw1yd40lyNsHmYuFqTrO6XxcDt2y1JEEo2zftv1E1Q4AzeZeIu7u3T4oJMjZNZog31XMNJmFvnabEdHFm93DyoR3yqFEXpsP/SgyiR/vVIOqU31Yq7/u5n4ijqDuVczJs9MCnV1jddLOoMQZeehTc607VFUQO8hRxewJquoBjSfKp3aM1fThrzqb+4k4grrjoG5kcfllbQW1u8a6zF9+eSfES2ck/av+KNWYYzXn5+Hd0sbqCWqblifKV9XVfKfTvpc988vPZizgbO4nsnN2b0vTbbOf1Mi/vrNodg3djM3TSZ8eVb/HuV/67+DOVZCsMN1bryrazeppCpLNbtH5fxHn647TFbRZdUp+Tl+YzQsFASgIQEEACgJQEICCABQEoCAABQEoCEBBAAoCUBCAggAUBKAgAAUBKAhAQYBxgszUE3Gy39QfwChBZf3TSDUwizQzxgjarts5OP5f2TJkjKDNqvkxsjqbRsYaBBjZB9kqxD4ogJ3EE/idP0tmHgeJk+FYguZNLh6xBZWnPhfiiWvQ+Jp7bI7bxE5AEwUBjtxJp2+IggBRBNXDRMXwVexMBcmbMXSPKnr/JkukJrZdL4YjnLsgeZfqffL1UXJnK2jf5CgIJEdBKLnUDVEQgIIAFASgIAAFAY4uKHVDFASgIAAFASgIcPxfNSgIJEdBIDkKAslREEiOgkByFISSS9sQBQEoCDBekDNDc558cxPkzPGdJ9/cBM0z9TljQc3MhCFPhVmCMLxgc8aC9kH7+fbjQHs8b0GblVq4WE9fCM20z1rQRi2DWQxcy1S9sRe7UIeVs6Dq4qOsF7qWhFC1pzzXGqSqhjrs0AxohVo5TlehKtRLi8Dn5DhsHKQEDV/t7bLPwWlUGQuqa1Ax6UGVjAXZPqgEU8hG5JubIDNUHHxnR8s+z2pkJ2hKdr5nNSgIJZeyoYPuxcAU39H55iXIXTM9CFxYIGdBht4qwl3wwgKZC1KVaKAG7fFYeM6C1Pc8w9+Z7bGwQMaCBtuW4cxrkKpC4DqGFxbIWtCufQ1GCLiwQO6C9mpp+yeXsKEDBBV7fGk/Mt+sBMnWs+eN6v75ZiUoRr6ZCdJvYJpYi3IWVNm3MM72hVlmgupR4LS1pTIWVN9HTPuJPmNBrEEoYoQ+KGFDaVzFMhMUIV8KqlMJrECVlyB9qz5xAcCcBZkJCeW0Tqifb7KGDrnM2xfWzniZz0rQ5idTdeYcKGYlqK5Bcw4UxxTkiTlooKgMzTtQHFOSp+WgL8zQAmUH5ZuNoGj5pmmIggAUBEhIUJqGIgkqhf1lccxyyWckSN2HbFbq92kK8mG+dNyuB6abe5NL0VAUQfXX1vJ2jYJ8NNNfigUFeam1yFE3BXmp79SCywL7k0vQUErjIArCyaVnKLagse/VSO59Eon8qjF7RrORWBObP6OppCcoMUORBI17VqMflpKiSAPFcc9qTMssLnFvNfacaT8tt7hEvVnd7fmsxrTc4pJoDdol84atWH3QqGc1QJSjmop0FRv3rEYwjjB/jmkowXGQE0e1M6EtHU3S0QSdDMcSND6SbWr1H110EyNmf560IP8++rQK3TeJ2pRtg/aUm4/zlO6UBHnTEE0lErvux8aV+VTba2qf67AN2vVDRpVmPiI0iuaouq5EXbfsFtvtC1sH247G7CZE97qZkaBQw9j7uye3dTbdc06CokBBAAoCUBCAI2nEkQTtlebEL43i7j4x+ixpUtC0cAqioGnhFERB08IpiIKmhecvKCsoCEBBAAoCUBCAggAUBKAgAAUBKAhAQQAKAlAQYHZBVXgdND0N/dVgJLM4TyBYLbK2CO/ePJI9UITxzC1ILdMUeHfUdi23l+oQg5EqPfsxEFzJMP3MtT9cPZKtF2gZKMIBzCzIzBQuvCub3y/18jL2DVy+SPoVcKE0zObg7tv1wmwdKsIBzCyokRCMIc9tMFJ59VYKCgTrlyuG82gE4SKMYm5B+iiGVrEqLm9DkeR21QcFgqvLv1e6CwuE100MF2EUMwsybX+gB1BT0AORVNtQggLBpXrGSNWTUB62b4ZFGMcTC6rqPtpnwL7+LRR8YWtGINy8Azao/1CetomZRxj8kfTWgSZmehXZwwR2r7uetJvYcA9pnzfzRyrtvJTrQBrmkOXh+8ObipN2Jz14jW2XJQhGKsKXefMwVhW6zBsvweCDecKBouogUKRiYKBY1vL84XUflPZAUbeUQOFsG1KhwUjmViMQXNV3Kv7wYjj4QHizCqAgAAUBKAhAQQAKAlAQgIIAFASgIAAFASgIQEEACgJQEICCABQEoCAABQEoCEBBAAoCUBCAggAUBKAgAAUBTkBQpSfHhhZHjc1pCNqsjqTndARNejXlFBIXpGayvL/4sJzyYspppC1ITYqqBGtQCDOtrqCgEGbeJvugICUFDcMaBLBTnikoiHlAhYLCmHEQBSUMBQEoCEBBAAoCUBCAggAUBKAgAAUBKAhAQQAKAlAQgIIAFASgIAAFASgIQEEACgJQEICCABQE+B9mjxHzQM2cTwAAAABJRU5ErkJggg==" /><!-- --></p>
<p><strong>From the power curve for t distribution, we can conclude that the power is very high when df is small, and it is decreasing as df increasing, this is because when the df is large, the limit distribution of t distribution is normal distribution, so that the power will be low if df is very large.</strong></p>
<hr />
</div>
</div>
<div id="exercise-6.8" class="section level2">
<h2>Exercise 6.8</h2>
<div id="question-13" class="section level3">
<h3>Question</h3>
<p><strong>Refer to Example 6.16. Repeat the simulation, but also compute the F test of equal variance, at significance level <span class="math inline">\(\alpha=0.055\)</span>. Compare the power of the Count Five test and F test for small, medium, and large sample sizes. (Recall that the F test is not applicable for non-normal distributions.)</strong></p>
</div>
<div id="answer-15" class="section level3">
<h3>Answer</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">12306</span>)
a &lt;-<span class="st"> </span><span class="fl">0.055</span>
n &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">10</span>,<span class="dv">30</span>,<span class="dv">50</span>,<span class="dv">100</span>,<span class="dv">200</span>,<span class="dv">500</span>)
mu1 &lt;-<span class="st"> </span>mu2 &lt;-<span class="st"> </span><span class="dv">0</span>
sigma1 &lt;-<span class="st"> </span><span class="dv">1</span>
sigma2 &lt;-<span class="st"> </span><span class="fl">1.5</span>
m &lt;-<span class="st"> </span><span class="fl">1e4</span>
result &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dv">0</span>, <span class="kw">length</span>(n), <span class="dv">2</span>)

countFtest &lt;-<span class="st"> </span><span class="cf">function</span>(x, y){
  X &lt;-<span class="st"> </span>x <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(x)
  Y &lt;-<span class="st"> </span>y <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(y)
  x1 &lt;-<span class="st"> </span><span class="kw">sum</span>(X <span class="op">&gt;</span><span class="st"> </span><span class="kw">max</span>(Y)) <span class="op">+</span><span class="st"> </span><span class="kw">sum</span>(X <span class="op">&lt;</span><span class="st"> </span><span class="kw">min</span>(Y))
  y1 &lt;-<span class="st"> </span><span class="kw">sum</span>(Y <span class="op">&gt;</span><span class="st"> </span><span class="kw">max</span>(X)) <span class="op">+</span><span class="st"> </span><span class="kw">sum</span>(Y <span class="op">&lt;</span><span class="st"> </span><span class="kw">min</span>(X))
<span class="kw">return</span> (<span class="kw">as.integer</span>(<span class="kw">max</span>(<span class="kw">c</span>(x1, y1)) <span class="op">&gt;</span><span class="st"> </span><span class="dv">5</span>))
}

<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(n)){ 
  ni &lt;-<span class="st"> </span>n[i]
  tests &lt;-<span class="st"> </span><span class="kw">replicate</span>(m, <span class="dt">expr=</span>{
  x &lt;-<span class="st"> </span><span class="kw">rnorm</span>(ni, mu1, sigma1)
  y &lt;-<span class="st"> </span><span class="kw">rnorm</span>(ni, mu2, sigma2)
  Fp &lt;-<span class="st"> </span><span class="kw">var.test</span>(x, y)<span class="op">$</span>p.value
  Ftest &lt;-<span class="st"> </span><span class="kw">as.integer</span>(Fp <span class="op">&lt;=</span><span class="st"> </span>a)
<span class="kw">c</span>(<span class="kw">countFtest</span>(x, y), Ftest)
})
result[i, ] &lt;-<span class="st"> </span><span class="kw">rowMeans</span>(tests)
}
<span class="kw">data.frame</span>(<span class="dt">n=</span>n, <span class="dt">CF=</span>result[, <span class="dv">1</span>], <span class="dt">Fp=</span>result[, <span class="dv">2</span>])</code></pre></div>
<pre><code>##     n     CF     Fp
## 1  10 0.1047 0.2167
## 2  30 0.4680 0.5913
## 3  50 0.6617 0.8167
## 4 100 0.8430 0.9807
## 5 200 0.9464 0.9998
## 6 500 0.9910 1.0000</code></pre>
<p><strong>From the result we can see that the F-test for equal variance is more powerful in this case, for all sample sizes compared.This may be because the F test is only applicable to the normal case, and the CF test is more general, so the power may be slightly worse.</strong></p>
<hr />
</div>
</div>
<div id="exercise-6.c" class="section level2">
<h2>Exercise 6.c</h2>
<div id="question-14" class="section level3">
<h3>Question</h3>
<p><strong>Repeat Examples 6.8 and 6.10 for Mardia multivariate skewness test. Mardia proposed tests of multivariate normality based on multivariate generalizations of skewness and kurtosis. If X and Y are iid, the multivariate population skewness <span class="math inline">\(\beta_{1,d}\)</span> is defined by Mardia as <span class="math display">\[\beta_{1,d}=E[(X-\mu)^{T}\Sigma^{-1}(X-\mu)]^{3},\]</span></strong></p>
<p><strong>Under normality,<span class="math inline">\(\beta_{1,d}=0\)</span>.The multivariate skewness statistic is:</strong></p>
<span class="math display">\[\begin{eqnarray*}
b_{1,d}=\dfrac{1}{n^2}\sum_{i,j=1}^{n}((X_i-\bar{X})^T\hat{\Sigma}^{-1}(X_j-\bar{X}))^3
\end{eqnarray*}\]</span>
<p><strong>where <span class="math inline">\(\hat{\Sigma}\)</span> is the maximum likelihood estimator of covariance. Large values of <span class="math inline">\(b_{1,d}\)</span> are significant. The asymptotic distribution of <span class="math inline">\(nb_{1,d}/6\)</span> is chisquared with d(d + 1)(d + 2)/6 degrees of freedom.</strong></p>
</div>
<div id="answer-16" class="section level3">
<h3>Answer</h3>
<strong>For multivariate normal distribution, the maximum likelihood estimator of covariance is sample covariance coefficient, which equals to:</strong>
<span class="math display">\[\begin{eqnarray*}
\hat{\Sigma}=\dfrac{1}{n}\sum_{i=1}^{n}(x_i-u)(x_i-u)^T,
\end{eqnarray*}\]</span>
<p><strong>where <span class="math inline">\(n\)</span> is the size of sample. Then we repeat the Mardia multivariate skewness test according to the asymptotic distribution of <span class="math inline">\(nb_{1,d}/6\)</span>.</strong></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(MASS)
<span class="co">#computes the sample skewness sttistic</span>
mskr &lt;-<span class="st"> </span><span class="cf">function</span>(X){
n &lt;-<span class="st"> </span><span class="kw">nrow</span>(X)
xbar &lt;-<span class="st"> </span><span class="kw">colMeans</span>(X)
sigma.hat &lt;-<span class="st"> </span><span class="kw">cov</span>(X) <span class="op">*</span><span class="st"> </span>(n <span class="op">-</span><span class="st"> </span><span class="dv">1</span>) <span class="op">/</span><span class="st"> </span>n
b &lt;-<span class="st"> </span><span class="kw">sum</span>(((<span class="kw">t</span>(<span class="kw">t</span>(X) <span class="op">-</span><span class="st"> </span>xbar))<span class="op">%*%</span><span class="kw">solve</span>(sigma.hat)<span class="op">%*%</span>(<span class="kw">t</span>(X) <span class="op">-</span><span class="st"> </span>xbar))<span class="op">^</span><span class="dv">3</span>) <span class="op">/</span><span class="st"> </span>n<span class="op">^</span><span class="dv">2</span>
<span class="kw">return</span> (b)
}


alpha=<span class="fl">0.05</span> <span class="co"># the significance level</span>
d=<span class="dv">2</span> <span class="co"># the dimension of multivariate normal distribution</span>
sigma=<span class="kw">diag</span>(<span class="dv">10</span>,d) <span class="co"># the covariance of multivariate normal distribution</span>
n=<span class="kw">c</span>(<span class="dv">10</span>,<span class="dv">20</span>,<span class="dv">30</span>,<span class="dv">50</span>,<span class="dv">100</span>,<span class="dv">500</span>) <span class="co"># sample sizes</span>
cv=<span class="kw">qchisq</span>(<span class="dv">1</span><span class="op">-</span>alpha,d<span class="op">*</span>(d<span class="op">+</span><span class="dv">1</span>)<span class="op">*</span>(d<span class="op">+</span><span class="dv">2</span>)<span class="op">/</span><span class="dv">6</span>) <span class="co"># critical value for the skewness test</span>
p.reject=<span class="kw">numeric</span>(<span class="kw">length</span>(n)) <span class="co"># store sim. results</span>
m=<span class="dv">1000</span> 
<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(n)) {
  sktests=<span class="kw">numeric</span>(m) <span class="co"># test decisions</span>
  <span class="cf">for</span> (j <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>m) {
    x=<span class="kw">mvrnorm</span>(n[i],<span class="kw">rep</span>(<span class="dv">0</span>,d),sigma) 
    sktests[j]=<span class="kw">as.integer</span>(<span class="kw">abs</span>(n[i]<span class="op">*</span><span class="kw">mskr</span>(x)<span class="op">/</span><span class="dv">6</span>) <span class="op">&gt;=</span><span class="st"> </span>cv )
  }
  p.reject[i]=<span class="kw">mean</span>(sktests) <span class="co">#proportion rejected</span>
}
<span class="kw">data.frame</span>(<span class="dt">n=</span>n, <span class="dt">p.reject=</span>p.reject)</code></pre></div>
<p>** From the result, we can see that as sample size gets larger, the power of multivariate skewness test increases , which corresponds to our expectation.**</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="co"># repeat Example 6.10 for  multivariate skewness test.</span>
alpha=<span class="fl">0.1</span> <span class="co"># the significance level</span>
n=<span class="dv">30</span> <span class="co"># the size of sample</span>
m=<span class="dv">1000</span> <span class="co"># the number of replicates</span>
d=<span class="dv">2</span> <span class="co"># the dimension of multivariate normal distribution</span>
sigma1=<span class="kw">diag</span>(d)
sigma2=<span class="dv">100</span><span class="op">*</span><span class="kw">diag</span>(d)
epsilon=<span class="kw">c</span>(<span class="kw">seq</span>(<span class="dv">0</span>,<span class="fl">0.1</span>,<span class="fl">0.025</span>),<span class="kw">seq</span>(<span class="fl">0.15</span>,<span class="fl">0.4</span>,<span class="fl">0.05</span>),<span class="kw">seq</span>(<span class="fl">0.55</span>,<span class="dv">1</span>,<span class="fl">0.15</span>))
N=<span class="kw">length</span>(epsilon)
pwr=<span class="kw">numeric</span>(N)
cv=<span class="kw">qchisq</span>(<span class="dv">1</span><span class="op">-</span>alpha,d<span class="op">*</span>(d<span class="op">+</span><span class="dv">1</span>)<span class="op">*</span>(d<span class="op">+</span><span class="dv">2</span>)<span class="op">/</span><span class="dv">6</span>) <span class="co"># critical value for the skewness test</span>
<span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>N){
e=epsilon[i]
sktests &lt;-<span class="st"> </span><span class="kw">numeric</span>(m)
<span class="cf">for</span> (j <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>m) { 
x=<span class="kw">matrix</span>(<span class="dv">0</span>,n,d)
<span class="cf">for</span>(k <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n) {<span class="cf">if</span>(<span class="kw">runif</span>(<span class="dv">1</span>)<span class="op">&lt;=</span><span class="dv">1</span><span class="op">-</span>e) x[k,]=<span class="kw">mvrnorm</span>(<span class="dv">1</span>,<span class="kw">rep</span>(<span class="dv">0</span>,<span class="dv">2</span>),sigma1)
<span class="cf">else</span> x[k,]=<span class="kw">mvrnorm</span>(<span class="dv">1</span>,<span class="kw">rep</span>(<span class="dv">0</span>,<span class="dv">2</span>),sigma2) } 
sktests[j] &lt;-<span class="st"> </span><span class="kw">as.integer</span>(n<span class="op">*</span><span class="kw">abs</span>(<span class="kw">mskr</span>(x))<span class="op">/</span><span class="dv">6</span><span class="op">&gt;=</span><span class="st"> </span>cv)
}
pwr[i]=<span class="kw">mean</span>(sktests)
}
<span class="co">#plot power vs epsilon</span>
<span class="kw">plot</span>(epsilon, pwr, <span class="dt">type =</span> <span class="st">&quot;b&quot;</span>,<span class="dt">xlab =</span> <span class="kw">bquote</span>(epsilon),<span class="dt">ylim =</span> <span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">1</span>))
<span class="kw">abline</span>(<span class="dt">h=</span><span class="fl">0.1</span>, <span class="dt">lty =</span> <span class="dv">3</span>)
se=<span class="kw">sqrt</span>(pwr<span class="op">*</span>(<span class="dv">1</span><span class="op">-</span>pwr)<span class="op">/</span>m) <span class="co">#add standard errors</span>
<span class="kw">lines</span>(epsilon, pwr<span class="op">+</span>se, <span class="dt">lty =</span> <span class="dv">3</span>)
<span class="kw">lines</span>(epsilon, pwr<span class="op">-</span>se, <span class="dt">lty =</span> <span class="dv">3</span>)</code></pre></div>
</div>
</div>
<div id="discussion" class="section level2">
<h2>Discussion</h2>
<p><strong>If we obtain the power for two methods under a particular simulation setting with 10000 experiment, say 0.651 for one method, and 0.676 fo another method, Can we say the powers are different at 0.05 level?</strong></p>
<div id="what-is-the-corresponding-hypothesis-test-problem" class="section level3">
<h3>What is the corresponding hypothesis test problem?</h3>
<p><strong>The power for the first method is <span class="math inline">\(power1\)</span>,the other is<span class="math inline">\(power2\)</span>,then we get <span class="math display">\[H_{0}:power1=power2\leftrightarrow H_{1}:power1 \not= power2.\]</span></strong></p>
</div>
<div id="which-test-shall-we-use" class="section level3">
<h3>Which test shall we use?</h3>
<p><strong>We can use Z-test, paired t test and McNemar test. The two-sample is not suitable because the corresponding samples have relevance.</strong></p>
</div>
<div id="what-information-is-need-to-test-your-hypothesis" class="section level3">
<h3>What information is need to test your hypothesis?</h3>
<p><strong>Z-test:we use <span class="math display">\[\dfrac{\hat{power1}-\hat{power2}}{\sqrt{\hat{power1}(1-\hat{power1})/n+\hat{power2}(1-\hat{power2})/n}}\to N(0,1),\]</span> which we already had.</strong></p>
<p><strong>paired t test:we use <span class="math display">\[\dfrac{\bar(d)}{s_{d}/\sqrt{n}}\to t(n-1)\]</span>, which if H0 is rejected under one of the two methods,but not rejected under the other method,<span class="math inline">\(d_{i}=1\)</span>;otherwise<span class="math inline">\(d_{i}=0\)</span>,so we need every <span class="math inline">\(d_{i}\)</span>.</strong></p>
<p><strong>McNemar test:we use <span class="math display">\[\hat{\chi^{2}}=\frac{(b-c)^{2}}{b+c}\]</span>,where <span class="math inline">\(b=n*\hat{power1},c=n*(1-\hat{power2})\)</span>,which we had already known.</strong></p>
<hr />
</div>
</div>
<div id="exercise-7.1" class="section level2">
<h2>Exercise 7.1</h2>
<div id="question-15" class="section level3">
<h3>Question</h3>
<p><strong>Compute a jackknife estimate of the bias and the standard error of the correlation statistic in Example 7.2.</strong></p>
</div>
<div id="answer-17" class="section level3">
<h3>Answer</h3>
<p><strong>we calcualte the jackknife estimates of bias and standard error of <span class="math inline">\(\hat{theta}\)</span> following the standard steps, which means:</strong> <span class="math display">\[bisa_{jack}=(n-1)(\bar{\hat\theta}_{(\cdot)}-\hat\theta)\]</span></p>
<p><span class="math display">\[ sd_{jack}(\hat\theta) = \sqrt{\frac{n-1}n\sum_{i=1}^n(\hat\theta_{(i)}-\bar{\hat\theta}_{(\cdot)})^2}\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">12306</span>)
LSAT &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">576</span>,<span class="dv">635</span>,<span class="dv">558</span>,<span class="dv">578</span>,<span class="dv">666</span>,<span class="dv">580</span>,<span class="dv">555</span>,<span class="dv">661</span>,<span class="dv">651</span>,<span class="dv">605</span>,<span class="dv">653</span>,<span class="dv">575</span>,<span class="dv">545</span>,<span class="dv">572</span>,<span class="dv">594</span>)
GPA &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">339</span>,<span class="dv">330</span>,<span class="dv">281</span>,<span class="dv">303</span>,<span class="dv">344</span>,<span class="dv">307</span>,<span class="dv">300</span>,<span class="dv">343</span>,<span class="dv">336</span>,<span class="dv">313</span>,<span class="dv">312</span>,<span class="dv">274</span>,<span class="dv">276</span>,<span class="dv">288</span>,<span class="dv">296</span>)
x &lt;-<span class="st"> </span><span class="kw">cbind</span>(LSAT,GPA)
n &lt;-<span class="st"> </span><span class="dv">15</span>
b.cor &lt;-<span class="st"> </span><span class="cf">function</span>(x,i) <span class="kw">cor</span>(x[i,<span class="dv">1</span>],x[i,<span class="dv">2</span>])
theta.hat &lt;-<span class="st"> </span><span class="kw">b.cor</span>(x,<span class="dv">1</span><span class="op">:</span>n)
theta.jack &lt;-<span class="st"> </span><span class="kw">numeric</span>(n)
<span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n)theta.jack[i] &lt;-<span class="st"> </span><span class="kw">b.cor</span>(x,(<span class="dv">1</span><span class="op">:</span>n)[<span class="op">-</span>i])
bias.jack &lt;-<span class="st"> </span>(n<span class="op">-</span><span class="dv">1</span>)<span class="op">*</span>(<span class="kw">mean</span>(theta.jack)<span class="op">-</span>theta.hat)
se.jack &lt;-<span class="kw">sqrt</span>((n<span class="op">-</span><span class="dv">1</span>) <span class="op">*</span><span class="kw">mean</span>((theta.jack <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(theta.jack))<span class="op">^</span><span class="dv">2</span>))
<span class="kw">list</span>(<span class="dt">bias.jack=</span>bias.jack, <span class="dt">se.jack=</span>se.jack)</code></pre></div>
<pre><code>## $bias.jack
## [1] -0.006473623
## 
## $se.jack
## [1] 0.1425186</code></pre>
<hr />
</div>
</div>
<div id="exercise-7.5" class="section level2">
<h2>Exercise 7.5</h2>
<div id="question-16" class="section level3">
<h3>Question</h3>
<p><strong>Refer to Exercise 7.4. Compute 95% bootstrap confidence intervals for the mean time between failures <span class="math inline">\(\frac{1}{\lambda}\)</span> by the standard normal, basic, percentile, and BCa methods. Compare the intervals and explain why they may differ.</strong></p>
</div>
<div id="answer-18" class="section level3">
<h3>Answer</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">12306</span>)
<span class="kw">library</span>(boot)
x &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">3</span>,<span class="dv">5</span>,<span class="dv">7</span>,<span class="dv">18</span>,<span class="dv">43</span>,<span class="dv">85</span>,<span class="dv">91</span>,<span class="dv">98</span>,<span class="dv">100</span>,<span class="dv">130</span>,<span class="dv">230</span>,<span class="dv">487</span>)
<span class="kw">qqnorm</span>(x);<span class="kw">qqline</span>(x)
boot.mean &lt;-<span class="st"> </span><span class="cf">function</span>(x,i) <span class="kw">mean</span>(x[i])
de &lt;-<span class="st"> </span><span class="kw">boot</span>(<span class="dt">data=</span>x,<span class="dt">statistic=</span>boot.mean,<span class="dt">R=</span><span class="dv">2000</span>)
ci &lt;-<span class="st"> </span><span class="kw">boot.ci</span>(de,<span class="dt">type=</span><span class="kw">c</span>(<span class="st">&quot;norm&quot;</span>,<span class="st">&quot;basic&quot;</span>,<span class="st">&quot;perc&quot;</span>,<span class="st">&quot;bca&quot;</span>))
ci</code></pre></div>
<p><strong>The standard normal bootstrap confidence interval requires a large amount of sampled data,BUT here are only 12 datas.When the sampling distribution of the statistic is approximately normal, the percentile interval will agree with the normal interval.BUT the 12 datas is not normal according to qq plot,so they are different.BCa inteval adjusts for bias and skewness,so it may be the best,and because the sampling data is too small, the good interval will be larger,which meet the simulation result of this question.</strong></p>
<hr />
</div>
</div>
<div id="exercise-7.8" class="section level2">
<h2>Exercise 7.8</h2>
<div id="question-17" class="section level3">
<h3>Question</h3>
<p><strong>Refer to Exercise 7.7. Obtain the jackknife estimates of bias and standard error of <span class="math inline">\(\hat{\theta}\)</span>.</strong></p>
</div>
<div id="answer-19" class="section level3">
<h3>Answer</h3>
<p><strong>we calcualte the jackknife estimates of bias and standard error of <span class="math inline">\(\hat{theta}\)</span> following the standard steps, which means:</strong> <span class="math display">\[bisa_{jack}=(n-1)(\bar{\hat\theta}_{(\cdot)}-\hat\theta)\]</span></p>
<p><span class="math display">\[ sd_{jack}(\hat\theta) = \sqrt{\frac{n-1}n\sum_{i=1}^n(\hat\theta_{(i)}-\bar{\hat\theta}_{(\cdot)})^2}\]</span></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">12306</span>)
<span class="kw">library</span>(bootstrap)
n &lt;-<span class="st"> </span><span class="dv">88</span>
data &lt;-<span class="st"> </span>scor
lambda &lt;-<span class="st"> </span><span class="kw">eigen</span>(<span class="kw">var</span>(data))<span class="op">$</span>values
theta.hat &lt;-<span class="st"> </span>lambda[<span class="dv">1</span>]<span class="op">/</span><span class="kw">sum</span>(lambda)

theta.jack &lt;-<span class="st"> </span><span class="kw">numeric</span>(n)
m &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="dv">0</span>,<span class="dv">5</span>,<span class="dv">5</span>)
<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n){
  lambda &lt;-<span class="st"> </span><span class="kw">eigen</span>(<span class="kw">var</span>(data[<span class="op">-</span>i,]))<span class="op">$</span>values
  theta.jack[i] &lt;-<span class="st"> </span>lambda[<span class="dv">1</span>]<span class="op">/</span><span class="kw">sum</span>(lambda)
}


bias.jack &lt;-<span class="st"> </span>(n<span class="op">-</span><span class="dv">1</span>)<span class="op">*</span>(<span class="kw">mean</span>(theta.jack)<span class="op">-</span>theta.hat)
se.jack &lt;-<span class="kw">sqrt</span>((n<span class="op">-</span><span class="dv">1</span>) <span class="op">*</span><span class="kw">mean</span>((theta.jack <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(theta.jack))<span class="op">^</span><span class="dv">2</span>))
<span class="kw">list</span>(<span class="dt">bias.jack=</span>bias.jack, <span class="dt">se.jack=</span>se.jack)</code></pre></div>
<hr />
</div>
</div>
<div id="exercise-8.3" class="section level2">
<h2>Exercise 8.3</h2>
<div id="question-18" class="section level3">
<h3>Question</h3>
<p><strong>The Count 5 test for equal variances in Section 6.4 is based on the maximum number of extreme points. Example 6.15 shows that the Count 5 criterion is not applicable for unequal sample sizes. Implement a permutation test for equal variance based on the maximum number of extreme points that applies when sample sizes are not necessarily equal.</strong></p>
</div>
<div id="answer-20" class="section level3">
<h3>Answer</h3>
<p><strong>we use function maxout to calculate maximum number of extreme points in each (x,y) pair, if the null hypothesis is right, which means the variances of the two populations are same, then, after permuting z = c(x,y), we designate first n1 elements to be x, the left n2 elements to be y, <span class="math inline">\(n1,n2\)</span>, we get a replicate, their variances also should be equal, we calculate maximum number of extreme points using this replicate. Repeating this procedure many times, we can calculate p value, meanwhile, by repeating the experiments many times, we can calculating type I error rate and the power.</strong></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">12306</span>)

<span class="co"># calculate maximum number of extreme points for pair x,y</span>
maxout &lt;-<span class="st"> </span><span class="cf">function</span>(x, y) {
  X &lt;-<span class="st"> </span>x <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(x)
  Y &lt;-<span class="st"> </span>y <span class="op">-</span><span class="st"> </span><span class="kw">mean</span>(y)
  outx &lt;-<span class="st"> </span><span class="kw">sum</span>(X <span class="op">&gt;</span><span class="st"> </span><span class="kw">max</span>(Y)) <span class="op">+</span><span class="st"> </span><span class="kw">sum</span>(X <span class="op">&lt;</span><span class="st"> </span><span class="kw">min</span>(Y))
  outy &lt;-<span class="st"> </span><span class="kw">sum</span>(Y <span class="op">&gt;</span><span class="st"> </span><span class="kw">max</span>(X)) <span class="op">+</span><span class="st"> </span><span class="kw">sum</span>(Y <span class="op">&lt;</span><span class="st"> </span><span class="kw">min</span>(X))
  <span class="kw">return</span>(<span class="kw">max</span>(<span class="kw">c</span>(outx, outy)))
}

<span class="co"># the statistics passed to boot</span>
stat&lt;-<span class="cf">function</span>(z,ix,n){
  x&lt;-z[ix][<span class="dv">1</span><span class="op">:</span>n]
  y&lt;-z[ix][<span class="op">-</span>(<span class="dv">1</span><span class="op">:</span>n)]
  <span class="kw">maxout</span>(x,y)
}

<span class="co"># this function is used to calculate p value</span>
permu_count5&lt;-<span class="cf">function</span>(n1,n2,<span class="dt">mu=</span><span class="dv">0</span>,sd1,sd2){
  x&lt;-<span class="kw">rnorm</span>(n1,mu,sd1)
  y&lt;-<span class="kw">rnorm</span>(n2,mu,sd2)
  z&lt;-<span class="kw">c</span>(x,y)
  R=<span class="dv">999</span>
  boot_obj&lt;-<span class="kw">boot</span>(z,<span class="dt">statistic =</span> stat,<span class="dt">R=</span>R,<span class="dt">sim=</span><span class="st">'permutation'</span>,<span class="dt">n=</span>n1)
  count&lt;-<span class="kw">c</span>( boot_obj<span class="op">$</span>t0, boot_obj<span class="op">$</span>t)
  p.value&lt;-<span class="kw">mean</span>(count<span class="op">&gt;=</span>count[<span class="dv">1</span>])
  <span class="kw">return</span>(p.value)
}
n&lt;-<span class="dv">1000</span>
p_value&lt;-<span class="kw">numeric</span>(n)

<span class="co"># calculate the empirical type I error rate</span>
<span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n) p_value[i]&lt;-<span class="kw">permu_count5</span>(<span class="dt">n1=</span><span class="dv">20</span>,<span class="dt">n2=</span><span class="dv">30</span>,<span class="dt">sd1=</span><span class="dv">1</span>,<span class="dt">sd2=</span><span class="dv">1</span>)
<span class="kw">cat</span>(<span class="st">'the empirical type I error rate is:'</span>,<span class="kw">mean</span>(p_value<span class="op">&lt;</span><span class="fl">0.05</span>),<span class="st">'</span><span class="ch">\n</span><span class="st">'</span>)

<span class="co"># calculate the power</span>
<span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>n) p_value[i]&lt;-<span class="kw">permu_count5</span>(<span class="dt">n1=</span><span class="dv">20</span>,<span class="dt">n2=</span><span class="dv">30</span>,<span class="dt">sd1=</span><span class="dv">1</span>,<span class="dt">sd2=</span><span class="dv">2</span>)
<span class="kw">cat</span>(<span class="st">'the empirical power is:'</span>,<span class="kw">mean</span>(p_value<span class="op">&lt;</span><span class="fl">0.05</span>))</code></pre></div>
<hr />
</div>
</div>
<div id="discussion-1" class="section level2">
<h2>Discussion</h2>
<div id="question-19" class="section level3">
<h3>Question</h3>
<p><strong>Design experiments for evaluating the performance of the NN, energy, and ball methods in various situations.</strong></p>
<p>(1)Unequal variances and equal expectations<br />
(2)Unequal variances and unequal expectations<br />
(3)Non-normal distributions: t distribution with 1 df (heavy-tailed distribution), bimodal distribution (mixture of two normal distributions)<br />
(4)Unbalanced samples (say, 1 case versus 10 controls)</p>
</div>
<div id="answer-21" class="section level3">
<h3>Answer</h3>
<p><strong>In this experiment, we simulated the distribution of a two-dimensional random variable based on the textbook<Statistical Computing with R>, and adjusted the parameters to make the efficacy of the three methods distinguishable.</strong></p>
<p><strong>Since energy test and ball statistic test for equal distributions can be directly achieved by energy and Ball package. We should first write the function of the NN test. Below is the variable definition and NN function.</strong></p>
<p><strong>(1)Unequal variances and equal expectations</strong></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">12306</span>)
sd &lt;-<span class="st"> </span><span class="fl">1.5</span>
<span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>m){
  x &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">rnorm</span>(n1<span class="op">*</span>p),<span class="dt">ncol=</span>p)
  y &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">rnorm</span>(n2<span class="op">*</span>p,<span class="dt">sd=</span>sd),<span class="dt">ncol=</span>p)
  z &lt;-<span class="st"> </span><span class="kw">rbind</span>(x,y)
  p.values[i,<span class="dv">1</span>] &lt;-<span class="st"> </span><span class="kw">eqdist.nn</span>(z,N,k)<span class="op">$</span>p.value<span class="co">#NN method</span>
  p.values[i,<span class="dv">2</span>] &lt;-<span class="st"> </span><span class="kw">eqdist.etest</span>(z,<span class="dt">sizes=</span>N,<span class="dt">R=</span>R)<span class="op">$</span>p.value<span class="co">#energy methods</span>
  p.values[i,<span class="dv">3</span>] &lt;-<span class="st"> </span><span class="kw">bd.test</span>(<span class="dt">x=</span>x,<span class="dt">y=</span>y,<span class="dt">R=</span><span class="dv">999</span>,<span class="dt">seed=</span>i<span class="op">*</span><span class="dv">12345</span>)<span class="op">$</span>p.value<span class="co"># ball method</span>
}
alpha &lt;-<span class="st"> </span><span class="fl">0.05</span>;
(pow &lt;-<span class="st"> </span><span class="kw">colMeans</span>(p.values<span class="op">&lt;</span>alpha))

power &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">methods =</span> <span class="kw">c</span>(<span class="st">'NN'</span>,<span class="st">'energy'</span>,<span class="st">'Ball'</span>),pow)
<span class="kw">ggplot</span>(power,<span class="kw">aes</span>(methods,pow))<span class="op">+</span><span class="co">#plot</span>
<span class="st">  </span><span class="kw">geom_col</span>(<span class="dt">fill =</span> <span class="st">'palegreen3'</span>)<span class="op">+</span>
<span class="st">  </span><span class="kw">coord_flip</span>()</code></pre></div>
<p><strong>The power of ball method is better than NN and energy methods.</strong></p>
<p><strong>(2)Unequal variances and unequal expectations</strong></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">12306</span>)
mu &lt;-<span class="st"> </span><span class="fl">0.5</span>
sd &lt;-<span class="st"> </span><span class="fl">1.5</span>
<span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>m){
  x &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">rnorm</span>(n1<span class="op">*</span>p),<span class="dt">ncol=</span>p)
  y &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">rnorm</span>(n2<span class="op">*</span>p,<span class="dt">mean=</span>mu,<span class="dt">sd=</span>sd),<span class="dt">ncol=</span>p)
  z &lt;-<span class="st"> </span><span class="kw">rbind</span>(x,y)
  p.values[i,<span class="dv">1</span>] &lt;-<span class="st"> </span><span class="kw">eqdist.nn</span>(z,N,k)<span class="op">$</span>p.value<span class="co">#NN method</span>
  p.values[i,<span class="dv">2</span>] &lt;-<span class="st"> </span><span class="kw">eqdist.etest</span>(z,<span class="dt">sizes=</span>N,<span class="dt">R=</span>R)<span class="op">$</span>p.value<span class="co">#energy methods</span>
  p.values[i,<span class="dv">3</span>] &lt;-<span class="st"> </span><span class="kw">bd.test</span>(<span class="dt">x=</span>x,<span class="dt">y=</span>y,<span class="dt">R=</span><span class="dv">999</span>,<span class="dt">seed=</span>i<span class="op">*</span><span class="dv">12345</span>)<span class="op">$</span>p.value<span class="co"># ball method</span>
}
alpha &lt;-<span class="st"> </span><span class="fl">0.05</span>;
pow &lt;-<span class="st"> </span><span class="kw">colMeans</span>(p.values<span class="op">&lt;</span>alpha)
pow

power &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">methods =</span> <span class="kw">c</span>(<span class="st">'NN'</span>,<span class="st">'energy'</span>,<span class="st">'Ball'</span>),pow)
<span class="kw">ggplot</span>(power,<span class="kw">aes</span>(methods,pow))<span class="op">+</span><span class="co">#plot</span>
<span class="st">  </span><span class="kw">geom_col</span>(<span class="dt">fill =</span> <span class="st">'palegreen3'</span>)<span class="op">+</span>
<span class="st">  </span><span class="kw">coord_flip</span>()</code></pre></div>
<p><strong>The power of ball method is better than NN and energy methods.</strong></p>
<p><strong>(3)Non-normal distributions: t distribution with 1 df (heavy-tailed distribution), bimodal distribution (mixture of two normal distributions).</strong></p>
<p><strong>t distribution VS bimodal distribution</strong></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">12306</span>)
mu &lt;-<span class="st"> </span><span class="fl">0.5</span>
sd &lt;-<span class="st"> </span><span class="dv">2</span>
<span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>m){
  x &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">rt</span>(n1<span class="op">*</span>p,<span class="dt">df=</span><span class="dv">1</span>),<span class="dt">ncol=</span>p)
  y1 =<span class="st"> </span><span class="kw">rnorm</span>(n2<span class="op">*</span>p);  y2 =<span class="st"> </span><span class="kw">rnorm</span>(n2<span class="op">*</span>p,<span class="dt">mean=</span>mu,<span class="dt">sd=</span>sd)
  w =<span class="st"> </span><span class="kw">rbinom</span>(n, <span class="dv">1</span>, .<span class="dv">5</span>) <span class="co"># 50:50 random choice</span>
  y &lt;-<span class="st"> </span><span class="kw">matrix</span>(w<span class="op">*</span>y1 <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span><span class="op">-</span>w)<span class="op">*</span>y2,<span class="dt">ncol=</span>p)<span class="co"># normal mixture</span>
  z &lt;-<span class="st"> </span><span class="kw">rbind</span>(x,y)
  p.values[i,<span class="dv">1</span>] &lt;-<span class="st"> </span><span class="kw">eqdist.nn</span>(z,N,k)<span class="op">$</span>p.value<span class="co">#NN method</span>
  p.values[i,<span class="dv">2</span>] &lt;-<span class="st"> </span><span class="kw">eqdist.etest</span>(z,<span class="dt">sizes=</span>N,<span class="dt">R=</span>R)<span class="op">$</span>p.value<span class="co">#energy methods</span>
  p.values[i,<span class="dv">3</span>] &lt;-<span class="st"> </span><span class="kw">bd.test</span>(<span class="dt">x=</span>x,<span class="dt">y=</span>y,<span class="dt">R=</span><span class="dv">999</span>,<span class="dt">seed=</span>i<span class="op">*</span><span class="dv">12345</span>)<span class="op">$</span>p.value<span class="co"># ball method</span>
}
alpha &lt;-<span class="st"> </span><span class="fl">0.05</span>;
pow &lt;-<span class="st"> </span><span class="kw">colMeans</span>(p.values<span class="op">&lt;</span>alpha)
pow

power &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">methods =</span> <span class="kw">c</span>(<span class="st">'NN'</span>,<span class="st">'energy'</span>,<span class="st">'Ball'</span>),pow)
<span class="kw">ggplot</span>(power,<span class="kw">aes</span>(methods,pow))<span class="op">+</span>
<span class="st">  </span><span class="kw">geom_col</span>(<span class="dt">fill =</span> <span class="st">'palegreen3'</span>)<span class="op">+</span>
<span class="st">  </span><span class="kw">coord_flip</span>()</code></pre></div>
<p><strong>The power of energy method is better than NN and ball methods.</strong></p>
<p><strong>t distribution VS normal distribution</strong></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">12306</span>)
<span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>m){
  x &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">rt</span>(n1<span class="op">*</span>p,<span class="dt">df=</span><span class="dv">1</span>),<span class="dt">ncol=</span>p)
  y &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">rnorm</span>(n2<span class="op">*</span>p,<span class="dt">sd=</span><span class="fl">1.5</span>),<span class="dt">ncol=</span>p)
  z &lt;-<span class="st"> </span><span class="kw">rbind</span>(x,y)
  p.values[i,<span class="dv">1</span>] &lt;-<span class="st"> </span><span class="kw">eqdist.nn</span>(z,N,k)<span class="op">$</span>p.value<span class="co">#NN method</span>
  p.values[i,<span class="dv">2</span>] &lt;-<span class="st"> </span><span class="kw">eqdist.etest</span>(z,<span class="dt">sizes=</span>N,<span class="dt">R=</span>R)<span class="op">$</span>p.value<span class="co">#energy methods</span>
  p.values[i,<span class="dv">3</span>] &lt;-<span class="st"> </span><span class="kw">bd.test</span>(<span class="dt">x=</span>x,<span class="dt">y=</span>y,<span class="dt">R=</span><span class="dv">999</span>,<span class="dt">seed=</span>i<span class="op">*</span><span class="dv">12345</span>)<span class="op">$</span>p.value<span class="co"># ball method</span>
}
alpha &lt;-<span class="st"> </span><span class="fl">0.05</span>;
pow &lt;-<span class="st"> </span><span class="kw">colMeans</span>(p.values<span class="op">&lt;</span>alpha)
pow

power &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">methods =</span> <span class="kw">c</span>(<span class="st">'NN'</span>,<span class="st">'energy'</span>,<span class="st">'Ball'</span>),pow)
<span class="kw">ggplot</span>(power,<span class="kw">aes</span>(methods,pow))<span class="op">+</span>
<span class="st">  </span><span class="kw">geom_col</span>(<span class="dt">fill =</span> <span class="st">'palegreen3'</span>)<span class="op">+</span>
<span class="st">  </span><span class="kw">coord_flip</span>()</code></pre></div>
<p><strong>The power of energy method is better than NN and ball methods.</strong></p>
<p><strong>bimodal distribution VS normal distribution</strong></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">12306</span>)
mu &lt;-<span class="st"> </span><span class="fl">0.5</span>
sd &lt;-<span class="st"> </span><span class="dv">2</span>
<span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>m){
  x &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">rnorm</span>(n1<span class="op">*</span>p),<span class="dt">ncol=</span>p)
  y1 =<span class="st"> </span><span class="kw">rnorm</span>(n2<span class="op">*</span>p);  y2 =<span class="st"> </span><span class="kw">rnorm</span>(n2<span class="op">*</span>p,<span class="dt">mean=</span>mu,<span class="dt">sd=</span>sd)
  w =<span class="st"> </span><span class="kw">rbinom</span>(n, <span class="dv">1</span>, .<span class="dv">5</span>) <span class="co"># 50:50 random choice</span>
  y &lt;-<span class="st"> </span><span class="kw">matrix</span>(w<span class="op">*</span>y1 <span class="op">+</span><span class="st"> </span>(<span class="dv">1</span><span class="op">-</span>w)<span class="op">*</span>y2,<span class="dt">ncol=</span>p)<span class="co"># normal mixture</span>
  z &lt;-<span class="st"> </span><span class="kw">rbind</span>(x,y)
  p.values[i,<span class="dv">1</span>] &lt;-<span class="st"> </span><span class="kw">eqdist.nn</span>(z,N,k)<span class="op">$</span>p.value<span class="co">#NN method</span>
  p.values[i,<span class="dv">2</span>] &lt;-<span class="st"> </span><span class="kw">eqdist.etest</span>(z,<span class="dt">sizes=</span>N,<span class="dt">R=</span>R)<span class="op">$</span>p.value<span class="co">#energy methods</span>
  p.values[i,<span class="dv">3</span>] &lt;-<span class="st"> </span><span class="kw">bd.test</span>(<span class="dt">x=</span>x,<span class="dt">y=</span>y,<span class="dt">R=</span><span class="dv">999</span>,<span class="dt">seed=</span>i<span class="op">*</span><span class="dv">12345</span>)<span class="op">$</span>p.value<span class="co"># ball method</span>
}
alpha &lt;-<span class="st"> </span><span class="fl">0.05</span>;
pow &lt;-<span class="st"> </span><span class="kw">colMeans</span>(p.values<span class="op">&lt;</span>alpha)
pow

power &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">methods =</span> <span class="kw">c</span>(<span class="st">'NN'</span>,<span class="st">'energy'</span>,<span class="st">'Ball'</span>),pow)
<span class="kw">ggplot</span>(power,<span class="kw">aes</span>(methods,pow))<span class="op">+</span><span class="co">#plot</span>
<span class="st">  </span><span class="kw">geom_col</span>(<span class="dt">fill =</span> <span class="st">'palegreen3'</span>)<span class="op">+</span>
<span class="st">  </span><span class="kw">coord_flip</span>()</code></pre></div>
<p><strong>The power of ball method is better than NN and energy methods.</strong></p>
<p><strong>(4)Unbalanced samples (say, 1 case versus 10 controls)</strong></p>
<p><strong>Without loss of generality, we make the control groups the same distribution and simply increase the sample size for calculation.</strong></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">12306</span>)
N =<span class="st"> </span><span class="kw">c</span>(n1,n2<span class="op">*</span><span class="dv">10</span>)
<span class="cf">for</span>(i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>m){
  x &lt;-<span class="st"> </span><span class="kw">matrix</span>(<span class="kw">rnorm</span>(n1<span class="op">*</span>p),<span class="dt">ncol=</span>p);
  y &lt;-<span class="st"> </span><span class="kw">cbind</span>(<span class="kw">rnorm</span>(n2<span class="op">*</span><span class="dv">10</span>),<span class="kw">rnorm</span>(n2<span class="op">*</span><span class="dv">10</span>,<span class="dt">mean =</span> <span class="fl">0.5</span>));
  z &lt;-<span class="st"> </span><span class="kw">rbind</span>(x,y)
  p.values[i,<span class="dv">1</span>] &lt;-<span class="st"> </span><span class="kw">eqdist.nn</span>(z,N,k)<span class="op">$</span>p.value<span class="co">#NN method</span>
  p.values[i,<span class="dv">2</span>] &lt;-<span class="st"> </span><span class="kw">eqdist.etest</span>(z,<span class="dt">sizes=</span>N,<span class="dt">R=</span>R)<span class="op">$</span>p.value<span class="co">#energy methods</span>
  p.values[i,<span class="dv">3</span>] &lt;-<span class="st"> </span><span class="kw">bd.test</span>(<span class="dt">x=</span>x,<span class="dt">y=</span>y,<span class="dt">R=</span><span class="dv">999</span>,<span class="dt">seed=</span>i<span class="op">*</span><span class="dv">12345</span>)<span class="op">$</span>p.value<span class="co"># ball method</span>
}
alpha &lt;-<span class="st"> </span><span class="fl">0.05</span>;
pow &lt;-<span class="st"> </span><span class="kw">colMeans</span>(p.values<span class="op">&lt;</span>alpha)
pow

power &lt;-<span class="st"> </span><span class="kw">data.frame</span>(<span class="dt">methods =</span> <span class="kw">c</span>(<span class="st">'NN'</span>,<span class="st">'energy'</span>,<span class="st">'Ball'</span>),pow)
<span class="kw">ggplot</span>(power,<span class="kw">aes</span>(methods,pow))<span class="op">+</span>
<span class="st">  </span><span class="kw">geom_col</span>(<span class="dt">fill =</span> <span class="st">'palegreen3'</span>)<span class="op">+</span>
<span class="st">  </span><span class="kw">coord_flip</span>()</code></pre></div>
<p><strong>The power of energy method is better than NN and ball methods.</strong></p>
</div>
</div>
<div id="in-conclusion-energy-test-and-ball-test-are-generally-more-powerful-than-nearest-nn-test-but-the-former-two-cannot-beat-uniformly-each-other." class="section level2">
<h2>In conclusion Energy test and Ball test are generally more powerful than nearest NN test, but the former two cannot beat uniformly each other.</h2>
<hr />
</div>
<div id="exercise-9.4" class="section level2">
<h2>Exercise 9.4</h2>
<div id="question-20" class="section level3">
<h3>Question</h3>
<p><strong>Implement a random walk Metropolis sampler for generating the standard Laplace distribution. For the increment, simulate from a normal distribution. Compare the chains generated when different variances are used for the proposal distribution. Also, compute the acceptance rates of each chain.</strong></p>
</div>
<div id="answer-22" class="section level3">
<h3>Answer</h3>
<p>For standard Laplace distribution, the pdf is: <span class="math display">\[
f(x)=\frac{1}{2}e^{-|x|}
\]</span></p>
<p>its mean is 0 and its standard deviation is <span class="math inline">\(\sqrt{2}\)</span>, so most of the random numbers should within the range <span class="math inline">\(\lbrack-3\sqrt{2},3\sqrt{2}\rbrack\)</span>.</p>
<p>For the increment, we choose normal distibution with mean equals 0 and sd equals 0.05,0.5,2,16, we use function <strong>rw.Metropolis</strong> to plot the chains generated by different increments and calculate the acceptance rates.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">12306</span>)
<span class="co"># pdf of standard Laplace distribution</span>
laplace &lt;-<span class="st"> </span><span class="cf">function</span>(x) <span class="kw">return</span>(<span class="fl">0.5</span><span class="op">*</span><span class="kw">exp</span>(<span class="op">-</span><span class="kw">abs</span>(x)))

rw.Metropolis &lt;-<span class="st"> </span><span class="cf">function</span>(sigma, x0, N) {
<span class="co"># N is the number of iterations</span>
x &lt;-<span class="st"> </span><span class="kw">numeric</span>(N)
x[<span class="dv">1</span>] &lt;-<span class="st"> </span>x0 <span class="co"># x0 is the initial value</span>
u &lt;-<span class="st"> </span><span class="kw">runif</span>(N) <span class="co"># u determines whether accept Y as x(t+1) or not</span>
k &lt;-<span class="st"> </span><span class="dv">0</span> <span class="co"># k denotes the times of rejection</span>

<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">2</span><span class="op">:</span>N) {
  <span class="co"># the candidate is from x[i-1] plus a normal increment ~ N(0,sigma)</span>
  y &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">1</span>, x[i <span class="op">-</span><span class="st"> </span><span class="dv">1</span>], sigma)
  <span class="cf">if</span> (u[i] <span class="op">&lt;=</span><span class="st"> </span>(<span class="kw">laplace</span>(y) <span class="op">/</span><span class="st"> </span><span class="kw">laplace</span>(x[i <span class="op">-</span><span class="st"> </span><span class="dv">1</span>])))
  x[i] &lt;-<span class="st"> </span>y
  <span class="cf">else</span> {
  x[i] &lt;-<span class="st"> </span>x[i <span class="op">-</span><span class="st"> </span><span class="dv">1</span>]
  k &lt;-<span class="st"> </span>k <span class="op">+</span><span class="st"> </span><span class="dv">1</span>
  }
}
<span class="kw">return</span>(<span class="kw">list</span>(<span class="dt">x =</span> x, <span class="dt">k =</span> k))
}

sigma &lt;-<span class="st"> </span><span class="kw">c</span>(.<span class="dv">05</span>, <span class="fl">0.5</span>, <span class="dv">2</span>, <span class="dv">16</span>);N &lt;-<span class="st"> </span><span class="dv">2000</span>;x0 &lt;-<span class="st"> </span><span class="dv">25</span>
rw1 &lt;-<span class="st"> </span><span class="kw">rw.Metropolis</span>( sigma[<span class="dv">1</span>], x0, N)
rw2 &lt;-<span class="st"> </span><span class="kw">rw.Metropolis</span>( sigma[<span class="dv">2</span>], x0, N)
rw3 &lt;-<span class="st"> </span><span class="kw">rw.Metropolis</span>( sigma[<span class="dv">3</span>], x0, N)
rw4 &lt;-<span class="st"> </span><span class="kw">rw.Metropolis</span>( sigma[<span class="dv">4</span>], x0, N)

<span class="kw">plot</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">2000</span>,rw1<span class="op">$</span>x,<span class="dt">type=</span><span class="st">'l'</span>,<span class="dt">ylab=</span><span class="st">&quot;x&quot;</span>,<span class="dt">xlab=</span><span class="st">'iteration'</span>,<span class="dt">main=</span><span class="st">'sd=0.05'</span>)
<span class="kw">abline</span>(<span class="dt">h=</span><span class="kw">c</span>(<span class="op">-</span><span class="dv">3</span><span class="op">*</span><span class="kw">sqrt</span>(<span class="dv">2</span>),<span class="dv">3</span><span class="op">*</span><span class="kw">sqrt</span>(<span class="dv">2</span>)))
<span class="kw">plot</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">2000</span>,rw2<span class="op">$</span>x,<span class="dt">type=</span><span class="st">'l'</span>,<span class="dt">ylab=</span><span class="st">&quot;x&quot;</span>,<span class="dt">xlab=</span><span class="st">'iteration'</span>,<span class="dt">main=</span><span class="st">'sd=0.5'</span>)
<span class="kw">abline</span>(<span class="dt">h=</span><span class="kw">c</span>(<span class="op">-</span><span class="dv">3</span><span class="op">*</span><span class="kw">sqrt</span>(<span class="dv">2</span>),<span class="dv">3</span><span class="op">*</span><span class="kw">sqrt</span>(<span class="dv">2</span>)))
<span class="kw">plot</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">2000</span>,rw3<span class="op">$</span>x,<span class="dt">type=</span><span class="st">'l'</span>,<span class="dt">ylab=</span><span class="st">&quot;x&quot;</span>,<span class="dt">xlab=</span><span class="st">'iteration'</span>,<span class="dt">main=</span><span class="st">'sd=2'</span>)
<span class="kw">abline</span>(<span class="dt">h=</span><span class="kw">c</span>(<span class="op">-</span><span class="dv">3</span><span class="op">*</span><span class="kw">sqrt</span>(<span class="dv">2</span>),<span class="dv">3</span><span class="op">*</span><span class="kw">sqrt</span>(<span class="dv">2</span>)))
<span class="kw">plot</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">2000</span>,rw4<span class="op">$</span>x,<span class="dt">type=</span><span class="st">'l'</span>,<span class="dt">ylab=</span><span class="st">&quot;x&quot;</span>,<span class="dt">xlab=</span><span class="st">'iteration'</span>,<span class="dt">main=</span><span class="st">'sd=16'</span>)
<span class="kw">abline</span>(<span class="dt">h=</span><span class="kw">c</span>(<span class="op">-</span><span class="dv">3</span><span class="op">*</span><span class="kw">sqrt</span>(<span class="dv">2</span>),<span class="dv">3</span><span class="op">*</span><span class="kw">sqrt</span>(<span class="dv">2</span>)))</code></pre></div>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">accept_rate&lt;-<span class="kw">c</span>(<span class="dv">1</span><span class="op">-</span>rw1<span class="op">$</span>k<span class="op">/</span>(N<span class="op">-</span><span class="dv">1</span>), <span class="dv">1</span><span class="op">-</span>rw2<span class="op">$</span>k<span class="op">/</span>(N<span class="op">-</span><span class="dv">1</span>), <span class="dv">1</span><span class="op">-</span>rw3<span class="op">$</span>k<span class="op">/</span>(N<span class="op">-</span><span class="dv">1</span>), <span class="dv">1</span><span class="op">-</span>rw4<span class="op">$</span>k<span class="op">/</span>(N<span class="op">-</span><span class="dv">1</span>))
<span class="kw">names</span>(accept_rate)&lt;-<span class="kw">c</span>(<span class="st">'sd=0.05'</span>,<span class="st">'sd=0.5'</span>,<span class="st">'sd=2'</span>,<span class="st">'sd=16'</span>)
<span class="kw">print</span>(accept_rate)</code></pre></div>
<p>From the result of the acceptance rates, we can conclude that, none of the four acceptance rates is within the range<span class="math inline">\(\lbrack 0.15,0.5\rbrack\)</span>, however, the third one is the nearest among the four increments, when sd equals 16, the acceptance rate is very low, so that we reject most of the candidate random numbers, this condition is inefficient. On the contrary, when sd equals 0.05 or 0.5, most of the candidates points are accepted so that the convergence speed is very slow.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">rw3 &lt;-<span class="st"> </span><span class="kw">rw.Metropolis</span>(<span class="dv">2</span>, <span class="dv">0</span>, <span class="dv">10000</span>)
y &lt;-<span class="st"> </span>rw3<span class="op">$</span>x[<span class="dv">1001</span><span class="op">:</span><span class="dv">10000</span>]
##Real density curve and histogram of random number generation
<span class="kw">hist</span>(y, <span class="dt">breaks=</span><span class="kw">seq</span>(<span class="op">-</span><span class="dv">10</span>,<span class="dv">10</span>, <span class="dt">by=</span><span class="fl">0.3</span>), 
       <span class="dt">freq=</span><span class="ot">FALSE</span>,<span class="dt">main=</span><span class="st">'MCMC of  standard Laplace'</span>)
<span class="kw">curve</span>(laplace, <span class="dt">from=</span><span class="op">-</span><span class="dv">10</span>, <span class="dt">to=</span><span class="dv">10</span>, <span class="dt">add=</span><span class="ot">TRUE</span>,<span class="dt">col=</span><span class="st">&quot;red&quot;</span>, <span class="dt">lwd=</span><span class="dv">3</span>)
##qqplot
a=<span class="kw">ppoints</span>(<span class="dv">100</span>)
QR=<span class="kw">c</span>(<span class="kw">log</span>(<span class="dv">2</span><span class="op">*</span>a[a<span class="op">&lt;=</span><span class="fl">0.5</span>]),<span class="op">-</span><span class="kw">log</span>(<span class="dv">2</span><span class="op">*</span>(<span class="dv">1</span><span class="op">-</span>a[a<span class="op">&gt;</span><span class="fl">0.5</span>]))) <span class="co">#quantiles of Laplace</span>
Q=<span class="kw">quantile</span>(y, a)
<span class="kw">qqplot</span>(QR, Q, <span class="dt">main=</span><span class="st">&quot;qqplot&quot;</span>,
       <span class="dt">xlab=</span><span class="st">&quot;Laplace Quantiles&quot;</span>, <span class="dt">ylab=</span><span class="st">&quot;Sample Quantiles&quot;</span>)
<span class="kw">lines</span>(<span class="kw">c</span>(<span class="kw">min</span>(y)<span class="op">-</span><span class="dv">1</span>,<span class="kw">max</span>(y)<span class="op">+</span><span class="dv">1</span>),<span class="kw">c</span>(<span class="kw">min</span>(y)<span class="op">-</span><span class="dv">1</span>,<span class="kw">max</span>(y)<span class="op">+</span><span class="dv">1</span>),<span class="dt">col=</span><span class="st">'blue'</span>)</code></pre></div>
<p>In conclusion, when sd equals 2, the random walk Metropolis sampler performs well.</p>
<hr />
</div>
</div>
<div id="exercise-9.4-extra" class="section level2">
<h2>Exercise 9.4 extra</h2>
<div id="question-21" class="section level3">
<h3>Question</h3>
<p><strong>use the Gelman-Rubin method to monitor convergence of the chain, and run the chain until it converges approximately to the target distribution according to R &lt; 1.2</strong></p>
</div>
<div id="answer-23" class="section level3">
<h3>Answer</h3>
<p><strong>To solve the problem,we use the method in Example 9.8.</strong></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">set.seed</span>(<span class="dv">12306</span>)
<span class="co"># the function for computing the mean of each chain</span>
Gelman.Rubin =<span class="st"> </span><span class="cf">function</span>(psi) {
  <span class="co"># psi[i,j] is the statistic psi(X[i,1:j])</span>
  <span class="co"># for chain in i-th row of X</span>
  psi =<span class="st"> </span><span class="kw">as.matrix</span>(psi)
  n =<span class="st"> </span><span class="kw">ncol</span>(psi)
  k =<span class="st"> </span><span class="kw">nrow</span>(psi)
  psi.means =<span class="st"> </span><span class="kw">rowMeans</span>(psi) <span class="co"># row means</span>
  B =<span class="st"> </span>n <span class="op">*</span><span class="st"> </span><span class="kw">var</span>(psi.means) <span class="co"># between variance est.</span>
  psi.w =<span class="st"> </span><span class="kw">apply</span>(psi, <span class="dv">1</span>, <span class="st">&quot;var&quot;</span>) <span class="co"># within variances</span>
  W =<span class="st"> </span><span class="kw">mean</span>(psi.w) <span class="co"># within est.</span>
  v.hat =<span class="st"> </span>W <span class="op">*</span><span class="st"> </span>(n <span class="op">-</span><span class="st"> </span><span class="dv">1</span>) <span class="op">/</span><span class="st"> </span>n <span class="op">+</span><span class="st"> </span>(B <span class="op">/</span><span class="st"> </span>n) <span class="co"># upper variance est.</span>
  r.hat =<span class="st"> </span>v.hat <span class="op">/</span><span class="st"> </span>W <span class="co"># G-R statistic</span>
  <span class="kw">return</span>(r.hat)
}

<span class="co"># implement a random walk Metropolis sampler</span>
rw.Metropolis =<span class="st"> </span><span class="cf">function</span>(sigma, x0, N) {
  x =<span class="st"> </span><span class="kw">numeric</span>(N)
  x[<span class="dv">1</span>] =<span class="st"> </span>x0
  u =<span class="st"> </span><span class="kw">runif</span>(N)
  <span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">2</span><span class="op">:</span>N) {
    y =<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">1</span>, x[i <span class="op">-</span><span class="st"> </span><span class="dv">1</span>], sigma)
    <span class="cf">if</span> (u[i] <span class="op">&lt;=</span><span class="st"> </span>(<span class="kw">laplace</span>(y) <span class="op">/</span><span class="st"> </span><span class="kw">laplace</span>(x[i <span class="op">-</span><span class="st"> </span><span class="dv">1</span>])))
      x[i] =<span class="st"> </span>y <span class="co"># accept y</span>
    <span class="cf">else</span>
      x[i] =<span class="st"> </span>x[i <span class="op">-</span><span class="st"> </span><span class="dv">1</span>]
  }
  <span class="kw">return</span>(x)
}

<span class="co"># set parameters</span>
k =<span class="st"> </span><span class="dv">4</span> <span class="co"># number of chains</span>
sigma =<span class="st"> </span><span class="dv">2</span> <span class="co"># variances</span>
n =<span class="st"> </span><span class="dv">10000</span> <span class="co"># length of each chain</span>
b =<span class="st"> </span><span class="dv">1000</span> <span class="co"># burn-in length</span>
x0 &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="op">-</span><span class="dv">30</span>,<span class="op">-</span><span class="dv">10</span>,  <span class="dv">10</span>, <span class="dv">30</span>) <span class="co"># initialize x0</span>

<span class="co"># generate the chains</span>
X =<span class="st"> </span><span class="kw">matrix</span>(<span class="dv">0</span>, <span class="dt">nrow =</span> k, <span class="dt">ncol =</span> n)
<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>k)
X[i, ] =<span class="st"> </span><span class="kw">rw.Metropolis</span>(sigma, x0[i], n)

<span class="co"># compute diagnostic statistics</span>
psi =<span class="st"> </span><span class="kw">t</span>(<span class="kw">apply</span>(X, <span class="dv">1</span>, cumsum))
<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">nrow</span>(psi))
psi[i, ] =<span class="st"> </span>psi[i, ] <span class="op">/</span><span class="st"> </span>(<span class="dv">1</span><span class="op">:</span><span class="kw">ncol</span>(psi))
<span class="kw">print</span>(<span class="kw">Gelman.Rubin</span>(psi))

<span class="co">#plot psi for the four chains</span>
<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span>k)
<span class="kw">plot</span>(psi[i, (b <span class="op">+</span><span class="st"> </span><span class="dv">1</span>)<span class="op">:</span>n],
<span class="dt">type =</span> <span class="st">&quot;l&quot;</span>,
<span class="dt">xlab =</span> i,
<span class="dt">ylab =</span> <span class="kw">bquote</span>(psi))

<span class="co">#plot the sequence of R-hat statistics</span>
rhat =<span class="st"> </span><span class="kw">rep</span>(<span class="dv">0</span>, n)
<span class="cf">for</span> (j <span class="cf">in</span> (b <span class="op">+</span><span class="st"> </span><span class="dv">1</span>)<span class="op">:</span>n)
rhat[j] =<span class="st"> </span><span class="kw">Gelman.Rubin</span>(psi[, <span class="dv">1</span><span class="op">:</span>j])
<span class="kw">plot</span>(rhat[(b <span class="op">+</span><span class="st"> </span><span class="dv">1</span>)<span class="op">:</span>n],
<span class="dt">type =</span> <span class="st">&quot;l&quot;</span>,
<span class="dt">xlab =</span> <span class="st">&quot;&quot;</span>,
<span class="dt">ylab =</span> <span class="st">&quot;R&quot;</span>)
<span class="kw">abline</span>(<span class="dt">h =</span> <span class="fl">1.2</span>, <span class="dt">lty =</span> <span class="dv">2</span>)</code></pre></div>
<hr />
</div>
</div>
<div id="exercise-11.4" class="section level2">
<h2>Exercise 11.4</h2>
<div id="question-22" class="section level3">
<h3>Question</h3>
<p><strong>Find the intersection points A(k) in (0 ,<span class="math inline">\(\sqrt k\)</span>) of the curves <span class="math display">\[S_{k-1}(a)=P \lgroup t(k-1) &gt;\sqrt {\frac {a^2(k-1)}{k-a^2} } \rgroup \]</span> and <span class="math display">\[ S_{k}(a)=P \lgroup t(k) &gt;\sqrt {\frac {a^2k}{k+1-a^2} } \rgroup \]</span> for k = 4 : 25 ,100,500,1000, where t(k) is a Student t random variable with k degrees of freedom.</strong></p>
</div>
<div id="answer-24" class="section level3">
<h3>Answer</h3>
<p>for the upper <span class="math inline">\(\sqrt k\)</span> is unavailable and the lower 0 is also a root ,first we add a small deviation : 1e-5. After the first part , we change the upper for the right answer.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">Sk_<span class="dv">1</span> &lt;-<span class="st"> </span><span class="cf">function</span>(a, k) {
  q &lt;-<span class="st"> </span><span class="kw">sqrt</span>(a <span class="op">^</span><span class="st"> </span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span>(k <span class="op">-</span><span class="st"> </span><span class="dv">1</span>) <span class="op">/</span><span class="st"> </span>(k <span class="op">-</span><span class="st"> </span>a <span class="op">^</span><span class="st"> </span><span class="dv">2</span>))
  <span class="kw">return</span> (<span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">pt</span>(q, <span class="dt">df =</span> k <span class="op">-</span><span class="st"> </span><span class="dv">1</span>))
}
Sk &lt;-<span class="st"> </span><span class="cf">function</span>(a, k) {
q &lt;-<span class="st"> </span><span class="kw">sqrt</span>(a <span class="op">^</span><span class="st"> </span><span class="dv">2</span> <span class="op">*</span><span class="st"> </span>k <span class="op">/</span><span class="st"> </span>(k <span class="op">+</span><span class="st"> </span><span class="dv">1</span> <span class="op">-</span><span class="st"> </span>a <span class="op">^</span><span class="st"> </span><span class="dv">2</span>))
<span class="kw">return</span> (<span class="dv">1</span> <span class="op">-</span><span class="st"> </span><span class="kw">pt</span>(q, <span class="dt">df =</span> k))
}
difSK &lt;-<span class="st"> </span><span class="cf">function</span>(x, k) {
<span class="kw">Sk_1</span>(x, k) <span class="op">-</span><span class="st"> </span><span class="kw">Sk</span>(x, k)
}
kset &lt;-<span class="st"> </span><span class="kw">c</span>(<span class="dv">4</span><span class="op">:</span><span class="dv">25</span>, <span class="dv">100</span>, <span class="dv">500</span>, <span class="dv">1000</span>)
out &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(kset)
<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(kset)) {
out[i] &lt;-<span class="st"> </span><span class="kw">uniroot</span>(
difSK,
<span class="dt">lower =</span> <span class="dv">0</span> <span class="op">+</span><span class="st"> </span><span class="fl">1e-5</span>,
<span class="dt">upper =</span> <span class="kw">sqrt</span>(kset[i]) <span class="op">-</span><span class="st"> </span><span class="fl">1e-5</span>,
<span class="dt">k =</span> kset[i]
)<span class="op">$</span>root
}
out</code></pre></div>
<p><strong>BUT not all anwser is right,we need change the algorithm.</strong></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">kset[<span class="kw">abs</span>(out<span class="op">-</span><span class="kw">sqrt</span>(kset)) <span class="op">&lt;</span><span class="st"> </span><span class="kw">sqrt</span>(kset)<span class="op">*</span><span class="fl">0.01</span>]</code></pre></div>
<p><strong>It is shown that when k large than 22,the root is a wrong ,so we change the algorithm.</strong></p>
<p><strong>based on the curve and the increasing of the answer,we change the upper.</strong></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">n &lt;-<span class="st"> </span><span class="dv">1</span><span class="op">:</span><span class="kw">length</span>(kset)
Kwrongnum &lt;-<span class="st"> </span>n[<span class="kw">abs</span>(out<span class="op">-</span><span class="kw">sqrt</span>(kset)) <span class="op">&lt;</span><span class="st"> </span><span class="kw">sqrt</span>(kset)<span class="op">*</span><span class="fl">0.01</span>]

<span class="co">#Example : k=23</span>
k=<span class="dv">23</span>
xx &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="fl">0.01</span>,<span class="kw">sqrt</span>(k)<span class="op">-</span><span class="fl">1e-5</span>,<span class="dt">length=</span><span class="dv">1000</span>)
y &lt;-<span class="st"> </span><span class="kw">difSK</span>(xx,k)
<span class="kw">plot</span>(xx,y,<span class="dt">type=</span><span class="st">&quot;l&quot;</span>,<span class="dt">col=</span><span class="st">&quot;red&quot;</span>)
<span class="kw">abline</span>(<span class="dt">h=</span><span class="dv">0</span>, <span class="dt">lty=</span><span class="dv">1</span>)

<span class="co">#Example : k=1000</span>
k=<span class="dv">1000</span>
xx &lt;-<span class="st"> </span><span class="kw">seq</span>(<span class="fl">0.01</span>,<span class="kw">sqrt</span>(k)<span class="op">-</span><span class="fl">1e-5</span>,<span class="dt">length=</span><span class="dv">1000</span>)
y &lt;-<span class="st"> </span><span class="kw">difSK</span>(xx,k)
<span class="kw">plot</span>(xx,y,<span class="dt">type=</span><span class="st">&quot;l&quot;</span>,<span class="dt">col=</span><span class="st">&quot;red&quot;</span>)
<span class="kw">abline</span>(<span class="dt">h=</span><span class="dv">0</span>, <span class="dt">lty=</span><span class="dv">1</span>)

<span class="co">#change upper to 3</span>

<span class="cf">for</span> (i <span class="cf">in</span> Kwrongnum) {
  out[i] &lt;-<span class="st"> </span><span class="kw">uniroot</span>(difSK,
  <span class="dt">lower =</span> <span class="dv">0</span> <span class="op">+</span><span class="st"> </span><span class="fl">1e-5</span>,
  <span class="dt">upper =</span> <span class="dv">3</span>,
  <span class="dt">k =</span> kset[i])<span class="op">$</span>root
}
<span class="kw">names</span>(out) &lt;-<span class="st"> </span>kset

out</code></pre></div>
<p><strong>Then we get the right answer.</strong></p>
<hr />
</div>
</div>
<div id="a-b-o-blood-type-problem" class="section level2">
<h2>A-B-O blood type problem</h2>
<div id="answer-25" class="section level3">
<h3>Answer</h3>
<p>We can see that the complete data likelihood is <span class="math display">\[l(p,q|n_{AA},n_{BB},n_{OO},n_{A.},n_{B.},n_{AB})=2n_{AA}log(p)+2n_{BB}log(q)+2n_{OO}log(r)+(n_{A.}-n_{AA})log(2pr)+(n_{B.}-n_{BB})log(2qr)+n_{AB}log(2pq) \]</span> where <span class="math inline">\(r=1-p-q\)</span>. and we can min <span class="math inline">\(-E[l(p,q|n_{AA},n_{BB},n_{OO},n_{A.},n_{B.},n_{AB})]\)</span>.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(nloptr)
<span class="co"># Mle function</span>
eval_f0 &lt;-<span class="st"> </span><span class="cf">function</span>(x,x1,<span class="dt">n.A=</span><span class="dv">444</span>,<span class="dt">n.B=</span><span class="dv">132</span>,<span class="dt">nOO=</span><span class="dv">361</span>,<span class="dt">nAB=</span><span class="dv">63</span>) {
  <span class="co">#x[1] mean p , x1[1] mean p0</span>
  <span class="co">#x[2] mean q , x1[2] mean q0</span>
  r1&lt;-<span class="dv">1</span><span class="op">-</span><span class="kw">sum</span>(x1)
  nAA&lt;-n.A<span class="op">*</span>x1[<span class="dv">1</span>]<span class="op">^</span><span class="dv">2</span><span class="op">/</span>(x1[<span class="dv">1</span>]<span class="op">^</span><span class="dv">2</span><span class="op">+</span><span class="dv">2</span><span class="op">*</span>x1[<span class="dv">1</span>]<span class="op">*</span>r1)
  nBB&lt;-n.B<span class="op">*</span>x1[<span class="dv">2</span>]<span class="op">^</span><span class="dv">2</span><span class="op">/</span>(x1[<span class="dv">2</span>]<span class="op">^</span><span class="dv">2</span><span class="op">+</span><span class="dv">2</span><span class="op">*</span>x1[<span class="dv">2</span>]<span class="op">*</span>r1)
  r&lt;-<span class="dv">1</span><span class="op">-</span><span class="kw">sum</span>(x)
  <span class="kw">return</span>(<span class="op">-</span><span class="dv">2</span><span class="op">*</span>nAA<span class="op">*</span><span class="kw">log</span>(x[<span class="dv">1</span>])<span class="op">-</span><span class="dv">2</span><span class="op">*</span>nBB<span class="op">*</span><span class="kw">log</span>(x[<span class="dv">2</span>])<span class="op">-</span><span class="dv">2</span><span class="op">*</span>nOO<span class="op">*</span><span class="kw">log</span>(r)<span class="op">-</span>
<span class="st">           </span>(n.A<span class="op">-</span>nAA)<span class="op">*</span><span class="kw">log</span>(<span class="dv">2</span><span class="op">*</span>x[<span class="dv">1</span>]<span class="op">*</span>r)<span class="op">-</span>(n.B<span class="op">-</span>nBB)<span class="op">*</span><span class="kw">log</span>(<span class="dv">2</span><span class="op">*</span>x[<span class="dv">2</span>]<span class="op">*</span>r)<span class="op">-</span>nAB<span class="op">*</span><span class="kw">log</span>(<span class="dv">2</span><span class="op">*</span>x[<span class="dv">1</span>]<span class="op">*</span>x[<span class="dv">2</span>]))
}


<span class="co"># constraint function </span>
eval_g0 &lt;-<span class="st"> </span><span class="cf">function</span>(x,x1,<span class="dt">n.A=</span><span class="dv">444</span>,<span class="dt">n.B=</span><span class="dv">132</span>,<span class="dt">nOO=</span><span class="dv">361</span>,<span class="dt">nAB=</span><span class="dv">63</span>) <span class="kw">return</span>(<span class="kw">sum</span>(x)<span class="op">-</span><span class="fl">0.999999</span>)


opts &lt;-<span class="st"> </span><span class="kw">list</span>(<span class="st">&quot;algorithm&quot;</span>=<span class="st">&quot;NLOPT_LN_COBYLA&quot;</span>,<span class="st">&quot;xtol_rel&quot;</span>=<span class="fl">1.0e-8</span>)
mle&lt;-<span class="ot">NULL</span>
r&lt;-<span class="kw">matrix</span>(<span class="dv">0</span>,<span class="dv">1</span>,<span class="dv">2</span>)
r&lt;-<span class="kw">rbind</span>(r,<span class="kw">c</span>(<span class="fl">0.2</span>,<span class="fl">0.35</span>))<span class="co"># the beginning value of p0 and q0</span>
j&lt;-<span class="dv">2</span>
<span class="cf">while</span> (<span class="kw">sum</span>(<span class="kw">abs</span>(r[j,]<span class="op">-</span>r[j<span class="op">-</span><span class="dv">1</span>,]))<span class="op">&gt;</span><span class="fl">1e-8</span>) {
res &lt;-<span class="st"> </span><span class="kw">nloptr</span>( <span class="dt">x0=</span><span class="kw">c</span>(<span class="fl">0.3</span>,<span class="fl">0.25</span>),
               <span class="dt">eval_f=</span>eval_f0,
               <span class="dt">lb =</span> <span class="kw">c</span>(<span class="dv">0</span>,<span class="dv">0</span>), <span class="dt">ub =</span> <span class="kw">c</span>(<span class="dv">1</span>,<span class="dv">1</span>), 
               <span class="dt">eval_g_ineq =</span> eval_g0, 
               <span class="dt">opts =</span> opts, <span class="dt">x1=</span>r[j,],<span class="dt">n.A=</span><span class="dv">444</span>,<span class="dt">n.B=</span><span class="dv">132</span>,<span class="dt">nOO=</span><span class="dv">361</span>,<span class="dt">nAB=</span><span class="dv">63</span>)
j&lt;-j<span class="op">+</span><span class="dv">1</span>
r&lt;-<span class="kw">rbind</span>(r,res<span class="op">$</span>solution)
mle&lt;-<span class="kw">c</span>(mle,<span class="kw">eval_f0</span>(<span class="dt">x=</span>r[j,],<span class="dt">x1=</span>r[j<span class="op">-</span><span class="dv">1</span>,]))
}
r  <span class="co">#the result of EM algorithm</span>
<span class="kw">list</span>(<span class="dt">mle=</span><span class="op">-</span>mle) <span class="co">#the max likelihood values</span></code></pre></div>
<p><strong>From the result,the mle is increasing and then unchanged.And the MLE of <span class="math inline">\(p\)</span> and <span class="math inline">\(q\)</span> is 0.2976407 and 0.1027063 respectively.</strong></p>
<hr />
</div>
</div>
<div id="exercise-3-p204" class="section level2">
<h2>Exercise 3 (p204)</h2>
<div id="question-23" class="section level3">
<h3>Question</h3>
<p><strong>Use both for loops and lapply to fit linear models to the mtcars.</strong></p>
</div>
<div id="answer-26" class="section level3">
<h3>Answer</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">formulas&lt;-<span class="kw">list</span>(
  mpg<span class="op">~</span>disp,
  mpg<span class="op">~</span><span class="kw">I</span>(<span class="dv">1</span><span class="op">/</span>disp),
  mpg<span class="op">~</span>disp<span class="op">+</span>wt,
  mpg<span class="op">~</span><span class="kw">I</span>(<span class="dv">1</span><span class="op">/</span>disp)<span class="op">+</span>wt
)

<span class="co"># lapply</span>
fit1&lt;-<span class="kw">lapply</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">4</span>,<span class="cf">function</span>(i) <span class="kw">lm</span>(<span class="dt">formula =</span> formulas[[i]],<span class="dt">data=</span>mtcars))

<span class="co"># forloop</span>

fit2&lt;-<span class="kw">vector</span>(<span class="st">'list'</span>,<span class="dt">length =</span> <span class="dv">4</span>)
<span class="cf">for</span>(i <span class="cf">in</span> <span class="kw">seq_along</span>(formulas)) fit2[[i]]&lt;-<span class="kw">lm</span>(<span class="dt">formula =</span> formulas[[i]],<span class="dt">data=</span>mtcars)

fit1
fit2</code></pre></div>
<hr />
</div>
</div>
<div id="exercise-3-p213" class="section level2">
<h2>Exercise 3 (p213)</h2>
<div id="question-24" class="section level3">
<h3>Question</h3>
<p><strong>Use sapply and an anonymous function to extract the p-value from every trial.</strong></p>
</div>
<div id="answer-27" class="section level3">
<h3>Answer</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">trials &lt;-<span class="st"> </span><span class="kw">replicate</span>(<span class="dv">100</span>,<span class="kw">t.test</span>(<span class="kw">rpois</span>(<span class="dv">10</span>, <span class="dv">10</span>), <span class="kw">rpois</span>(<span class="dv">7</span>, <span class="dv">10</span>)),<span class="dt">simplify =</span> <span class="ot">FALSE</span>)

<span class="co"># sapply with anonymous function</span>
pvalue&lt;-<span class="kw">sapply</span>(trials,<span class="cf">function</span>(test) test<span class="op">$</span>p.value)

<span class="co"># sapply without anonymous function</span>
pvalue1&lt;-<span class="kw">sapply</span>(trials,<span class="st">'[['</span>,<span class="st">'p.value'</span>)

pvalue
pvalue1</code></pre></div>
<hr />
</div>
</div>
<div id="exercise-6-p214" class="section level2">
<h2>Exercise 6 (p214)</h2>
<div id="question-25" class="section level3">
<h3>Question</h3>
<p><strong>Implement a combination of Map and vapply to create an lapply variant that iterates in parallel over all of its inputs and stores its outputs in a vector (or a matrix). What arguments should the function take?</strong></p>
</div>
<div id="answer-28" class="section level3">
<h3>Answer</h3>
<p><strong>As we understand this exercise, it is about working with a list of lists, like in the following example:</strong></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">testlist &lt;-<span class="st"> </span><span class="kw">list</span>(mtcars, cars)
<span class="kw">lapply</span>(testlist, <span class="cf">function</span>(x) <span class="kw">vapply</span>(x, mean, <span class="kw">numeric</span>(<span class="dv">1</span>)))</code></pre></div>
<p><strong>So we can get the same result with a more specialized function:</strong></p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r">lmapply &lt;-<span class="st"> </span><span class="cf">function</span>(X, f, f.value, <span class="dt">simplify =</span> <span class="ot">FALSE</span>) {
  out &lt;-<span class="st"> </span><span class="kw">Map</span>(<span class="cf">function</span>(x)
  <span class="kw">vapply</span>(x, f, f.value), X)
  <span class="cf">if</span> (simplify <span class="op">==</span><span class="st"> </span><span class="ot">TRUE</span>) {
  <span class="kw">return</span>(<span class="kw">simplify2array</span>(out))
  }
  <span class="kw">unlist</span>(out, <span class="dt">recursive =</span> <span class="ot">FALSE</span>)
}
<span class="kw">lmapply</span>(testlist, mean, <span class="kw">numeric</span>(<span class="dv">1</span>))</code></pre></div>
<p><strong>And we change the outcome from list to vector.Because the vector calculated from the components of the table may not be combined into a matrix, we converted it into a vector.But one problem is that you need to determine the composition of the result according to the subset of the table.All in all,we solve the problem.</strong></p>
<hr />
</div>
</div>
<div id="exercise-10.1" class="section level2">
<h2>Exercise 10.1</h2>
<div id="question-26" class="section level3">
<h3>Question</h3>
<p><strong>Rewrite an Rcpp function for the same task as in exercise 9.4.</strong></p>
</div>
<div id="answer-29" class="section level3">
<h3>Answer</h3>
<p>We write function <strong>rw.metropolis</strong> as the R random number generater, and <strong>Metropolis</strong> as the C++ random number generater (see attached), then we draw the figures under different variance scenarios.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(Rcpp)
## 1.  R random number generater

<span class="co"># pdf of standard Laplace distribution</span>
laplace&lt;-<span class="cf">function</span>(x) <span class="kw">return</span>(<span class="dv">1</span><span class="op">/</span><span class="dv">2</span><span class="op">*</span><span class="kw">exp</span>(<span class="op">-</span><span class="kw">abs</span>(x)))

rw.Metropolis &lt;-<span class="st"> </span><span class="cf">function</span>(sigma, x0, N) {
  
<span class="co"># N is the number of iterations</span>
x &lt;-<span class="st"> </span><span class="kw">numeric</span>(N)
<span class="co"># x0 is the initial value</span>
x[<span class="dv">1</span>] &lt;-<span class="st"> </span>x0

<span class="co"># u determines whether accept Y as x(t+1) or not</span>
u &lt;-<span class="st"> </span><span class="kw">runif</span>(N)

<span class="co"># k denotes the times of rejection</span>
k &lt;-<span class="st"> </span><span class="dv">0</span>

<span class="cf">for</span> (i <span class="cf">in</span> <span class="dv">2</span><span class="op">:</span>N) {
  <span class="co"># the candidate is from x[i-1] plus a normal increment ~ N(0,sigma)</span>
  y &lt;-<span class="st"> </span><span class="kw">rnorm</span>(<span class="dv">1</span>, x[i <span class="op">-</span><span class="st"> </span><span class="dv">1</span>], sigma)
  <span class="cf">if</span> (u[i] <span class="op">&lt;=</span><span class="st"> </span>(<span class="kw">laplace</span>(y) <span class="op">/</span><span class="st"> </span><span class="kw">laplace</span>(x[i <span class="op">-</span><span class="st"> </span><span class="dv">1</span>])))
  x[i] &lt;-<span class="st"> </span>y
  <span class="cf">else</span> {
  x[i] &lt;-<span class="st"> </span>x[i <span class="op">-</span><span class="st"> </span><span class="dv">1</span>]
  k &lt;-<span class="st"> </span>k <span class="op">+</span><span class="st"> </span><span class="dv">1</span>
  }
}
<span class="kw">return</span>(<span class="kw">list</span>(<span class="dt">x =</span> x, <span class="dt">k =</span> k))
}


## 2. C++ random number generater: function(Metropolis)
<span class="kw">library</span>(StatComp20064)


sigma &lt;-<span class="st"> </span><span class="kw">c</span>(.<span class="dv">05</span>, .<span class="dv">5</span>, <span class="dv">2</span>, <span class="dv">16</span>);N &lt;-<span class="st"> </span><span class="dv">2000</span>;x0 &lt;-<span class="st"> </span><span class="dv">25</span>

rw1 &lt;-<span class="st"> </span><span class="kw">rw.Metropolis</span>( sigma[<span class="dv">1</span>], x0, N)
rw2 &lt;-<span class="st"> </span><span class="kw">rw.Metropolis</span>( sigma[<span class="dv">2</span>], x0, N)
rw3 &lt;-<span class="st"> </span><span class="kw">rw.Metropolis</span>( sigma[<span class="dv">3</span>], x0, N)
rw4 &lt;-<span class="st"> </span><span class="kw">rw.Metropolis</span>( sigma[<span class="dv">4</span>], x0, N)

cpp.rw1&lt;-<span class="kw">Metropolis</span>( sigma[<span class="dv">1</span>], x0, N)
cpp.rw2&lt;-<span class="kw">Metropolis</span>( sigma[<span class="dv">2</span>], x0, N)
cpp.rw3&lt;-<span class="kw">Metropolis</span>( sigma[<span class="dv">3</span>], x0, N)
cpp.rw4&lt;-<span class="kw">Metropolis</span>( sigma[<span class="dv">4</span>], x0, N)


<span class="kw">plot</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">2000</span>,rw1<span class="op">$</span>x,<span class="dt">type=</span><span class="st">'l'</span>,<span class="dt">ylab=</span><span class="st">&quot;x&quot;</span>,<span class="dt">xlab=</span><span class="st">'iteration'</span>,<span class="dt">main=</span><span class="st">'sd=0.05(R)'</span>)

<span class="kw">plot</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">2000</span>,rw2<span class="op">$</span>x,<span class="dt">type=</span><span class="st">'l'</span>,<span class="dt">ylab=</span><span class="st">&quot;x&quot;</span>,<span class="dt">xlab=</span><span class="st">'iteration'</span>,<span class="dt">main=</span><span class="st">'sd=0.5(R)'</span>)
<span class="kw">abline</span>(<span class="dt">h=</span><span class="kw">c</span>(<span class="op">-</span><span class="dv">3</span><span class="op">*</span><span class="kw">sqrt</span>(<span class="dv">2</span>),<span class="dv">3</span><span class="op">*</span><span class="kw">sqrt</span>(<span class="dv">2</span>)))
<span class="kw">plot</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">2000</span>,rw3<span class="op">$</span>x,<span class="dt">type=</span><span class="st">'l'</span>,<span class="dt">ylab=</span><span class="st">&quot;x&quot;</span>,<span class="dt">xlab=</span><span class="st">'iteration'</span>,<span class="dt">main=</span><span class="st">'sd=2(R)'</span>)
<span class="kw">abline</span>(<span class="dt">h=</span><span class="kw">c</span>(<span class="op">-</span><span class="dv">3</span><span class="op">*</span><span class="kw">sqrt</span>(<span class="dv">2</span>),<span class="dv">3</span><span class="op">*</span><span class="kw">sqrt</span>(<span class="dv">2</span>)))
<span class="kw">plot</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">2000</span>,rw4<span class="op">$</span>x,<span class="dt">type=</span><span class="st">'l'</span>,<span class="dt">ylab=</span><span class="st">&quot;x&quot;</span>,<span class="dt">xlab=</span><span class="st">'iteration'</span>,<span class="dt">main=</span><span class="st">'sd=16(R)'</span>)
<span class="kw">abline</span>(<span class="dt">h=</span><span class="kw">c</span>(<span class="op">-</span><span class="dv">3</span><span class="op">*</span><span class="kw">sqrt</span>(<span class="dv">2</span>),<span class="dv">3</span><span class="op">*</span><span class="kw">sqrt</span>(<span class="dv">2</span>)))


<span class="kw">plot</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">2000</span>,cpp.rw1[,<span class="dv">1</span>],<span class="dt">type=</span><span class="st">'l'</span>,<span class="dt">ylab=</span><span class="st">&quot;x&quot;</span>,<span class="dt">xlab=</span><span class="st">'iteration'</span>,<span class="dt">main=</span><span class="st">'sd=0.05(Cpp)'</span>)
<span class="kw">plot</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">2000</span>,cpp.rw2[,<span class="dv">1</span>],<span class="dt">type=</span><span class="st">'l'</span>,<span class="dt">ylab=</span><span class="st">&quot;x&quot;</span>,<span class="dt">xlab=</span><span class="st">'iteration'</span>,<span class="dt">main=</span><span class="st">'sd=0.5(Cpp)'</span>)
<span class="kw">abline</span>(<span class="dt">h=</span><span class="kw">c</span>(<span class="op">-</span><span class="dv">3</span><span class="op">*</span><span class="kw">sqrt</span>(<span class="dv">2</span>),<span class="dv">3</span><span class="op">*</span><span class="kw">sqrt</span>(<span class="dv">2</span>)))
<span class="kw">plot</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">2000</span>,cpp.rw3[,<span class="dv">1</span>],<span class="dt">type=</span><span class="st">'l'</span>,<span class="dt">ylab=</span><span class="st">&quot;x&quot;</span>,<span class="dt">xlab=</span><span class="st">'iteration'</span>,<span class="dt">main=</span><span class="st">'sd=2(Cpp)'</span>)
<span class="kw">abline</span>(<span class="dt">h=</span><span class="kw">c</span>(<span class="op">-</span><span class="dv">3</span><span class="op">*</span><span class="kw">sqrt</span>(<span class="dv">2</span>),<span class="dv">3</span><span class="op">*</span><span class="kw">sqrt</span>(<span class="dv">2</span>)))
<span class="kw">plot</span>(<span class="dv">1</span><span class="op">:</span><span class="dv">2000</span>,cpp.rw4[,<span class="dv">1</span>],<span class="dt">type=</span><span class="st">'l'</span>,<span class="dt">ylab=</span><span class="st">&quot;x&quot;</span>,<span class="dt">xlab=</span><span class="st">'iteration'</span>,<span class="dt">main=</span><span class="st">'sd=16(Cpp)'</span>)
<span class="kw">abline</span>(<span class="dt">h=</span><span class="kw">c</span>(<span class="op">-</span><span class="dv">3</span><span class="op">*</span><span class="kw">sqrt</span>(<span class="dv">2</span>),<span class="dv">3</span><span class="op">*</span><span class="kw">sqrt</span>(<span class="dv">2</span>)))</code></pre></div>
<hr />
</div>
</div>
<div id="exercise-10.2" class="section level2">
<h2>Exercise 10.2</h2>
<div id="question-27" class="section level3">
<h3>Question</h3>
<p><strong>Compare the generated random numbers by the two functions using qqplot.</strong></p>
</div>
<div id="answer-30" class="section level3">
<h3>Answer</h3>
<p>Because after 500 iterations, the distribution of the random numbers generated by both methods are stable except the scenario sd=0.05, so we use <strong>qqplot</strong> to contrast the data points after the 500th iterations.</p>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">qqplot</span>(rw1<span class="op">$</span>x[<span class="dv">500</span><span class="op">:</span><span class="dv">2000</span>],cpp.rw1[<span class="dv">500</span><span class="op">:</span><span class="dv">2000</span>,<span class="dv">1</span>],<span class="dt">xlab=</span><span class="st">'R'</span>,<span class="dt">ylab=</span><span class="st">'cpp'</span>,<span class="dt">main=</span><span class="st">'sd=0.05'</span>)
<span class="kw">qqplot</span>(rw2<span class="op">$</span>x[<span class="dv">500</span><span class="op">:</span><span class="dv">2000</span>],cpp.rw2[<span class="dv">500</span><span class="op">:</span><span class="dv">2000</span>,<span class="dv">1</span>],<span class="dt">xlab=</span><span class="st">'R'</span>,<span class="dt">ylab=</span><span class="st">'cpp'</span>,<span class="dt">main=</span><span class="st">'sd=0.5'</span>)
<span class="kw">qqplot</span>(rw3<span class="op">$</span>x[<span class="dv">500</span><span class="op">:</span><span class="dv">2000</span>],cpp.rw3[<span class="dv">500</span><span class="op">:</span><span class="dv">2000</span>,<span class="dv">1</span>],<span class="dt">xlab=</span><span class="st">'R'</span>,<span class="dt">ylab=</span><span class="st">'cpp'</span>,<span class="dt">main=</span><span class="st">'sd=2'</span>)
<span class="kw">qqplot</span>(rw4<span class="op">$</span>x[<span class="dv">500</span><span class="op">:</span><span class="dv">2000</span>],cpp.rw4[<span class="dv">500</span><span class="op">:</span><span class="dv">2000</span>,<span class="dv">1</span>],<span class="dt">xlab=</span><span class="st">'R'</span>,<span class="dt">ylab=</span><span class="st">'cpp'</span>,<span class="dt">main=</span><span class="st">'sd=16'</span>)</code></pre></div>
<p>As the qqplots show, the distributions of the random numbers are similiar when sd = 0.5 or 2, when sd = 0.05, since both distributions are not stable so that they are not similiar, when sd = 16, Although most of the candidates are rejected, however, they are also similar in the interval [-2,2].</p>
<hr />
</div>
</div>
<div id="exercise-10.3" class="section level2">
<h2>Exercise 10.3</h2>
<div id="question-28" class="section level3">
<h3>Question</h3>
<p><strong>Campare the computation time of the two functions using microbenchmark.</strong></p>
</div>
<div id="answer-31" class="section level3">
<h3>Answer</h3>
<div class="sourceCode"><pre class="sourceCode r"><code class="sourceCode r"><span class="kw">library</span>(microbenchmark)
n &lt;-<span class="st"> </span><span class="dv">2000</span>
ts1 &lt;-
<span class="kw">microbenchmark</span>(<span class="dt">R =</span> <span class="kw">rw.Metropolis</span>(<span class="fl">0.05</span>, <span class="dv">25</span>, n), <span class="dt">cpp =</span> <span class="kw">Metropolis</span>(<span class="fl">0.05</span>, <span class="dv">25</span>, n))

ts2 &lt;-
<span class="kw">microbenchmark</span>(<span class="dt">R =</span> <span class="kw">rw.Metropolis</span>(<span class="fl">0.5</span>, <span class="dv">25</span>, n), <span class="dt">cpp =</span> <span class="kw">Metropolis</span>(<span class="fl">0.5</span>, <span class="dv">25</span>, n))

ts3 &lt;-
<span class="kw">microbenchmark</span>(<span class="dt">R =</span> <span class="kw">rw.Metropolis</span>(<span class="dv">2</span>, <span class="dv">25</span>, n), <span class="dt">cpp =</span> <span class="kw">Metropolis</span>(<span class="dv">2</span>, <span class="dv">25</span>, n))

ts4 &lt;-
<span class="kw">microbenchmark</span>(<span class="dt">R =</span> <span class="kw">rw.Metropolis</span>(<span class="dv">16</span>, <span class="dv">25</span>, n), <span class="dt">cpp =</span> <span class="kw">Metropolis</span>(<span class="dv">16</span>, <span class="dv">25</span>, n))

<span class="kw">summary</span>(ts1)[, <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">5</span>, <span class="dv">6</span>)]
<span class="kw">summary</span>(ts2)[, <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">5</span>, <span class="dv">6</span>)]
<span class="kw">summary</span>(ts3)[, <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">5</span>, <span class="dv">6</span>)]
<span class="kw">summary</span>(ts4)[, <span class="kw">c</span>(<span class="dv">1</span>, <span class="dv">3</span>, <span class="dv">5</span>, <span class="dv">6</span>)]</code></pre></div>
<p>The result above shows that the process executed by Rcpp function <strong>Metropolis</strong> is much faster than the original R function <strong>rw.Metropolis</strong>, so that Rcpp is a way more efficient than R.</p>
</div>
</div>



<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
